{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction**\n",
    "\n",
    "1.  **Capture Historical Delay Patterns:**\n",
    "    * **Feature:** `Delay_Trend`\n",
    "    * **Goal:** Identify recurring delays between specific airport pairs during particular weeks.\n",
    "    * **Implementation:** Aggregate weekly delay data, focusing on the top 15 airports to manage memory and ensure generalizability.\n",
    "    * **Rationale:** Historical delay patterns are strong indicators of future delays.\n",
    "\n",
    "2.  **Assess Aircraft Reuse:**\n",
    "    * **Feature:** `Same_Day_Tail_Reuse`\n",
    "    * **Goal:** Determine if an aircraft is scheduled for multiple flights on the same day.\n",
    "    * **Rationale:** High reuse can lead to delay propagation.\n",
    "\n",
    "3.  **Calculate Turnaround Time:**\n",
    "    * **Feature:** `Turnaround_Time`\n",
    "    * **Goal:** Measure the time between an aircraft's arrival and its next scheduled departure.\n",
    "    * **Rationale:** Short turnaround times increase delay vulnerability.\n",
    "\n",
    "4.  **Determine Slack Time:**\n",
    "    * **Feature:** `Slack_Time`\n",
    "    * **Goal:** Calculate the difference between scheduled arrival and expected travel time.\n",
    "    * **Rationale:** Slack time indicates buffer capacity, which can absorb minor delays.\n",
    "\n",
    "**Outlier**\n",
    "\n",
    "1.  **Handle Extreme Aircraft Age Values:**\n",
    "    * **Feature:** `Aircraft_Age`\n",
    "    * **Issue:** Presence of unrealistic age values.\n",
    "    * **Solution:** Clip outliers to a realistic maximum (e.g., 56.9 years).\n",
    "    * **Rationale:** Prevent outliers from skewing model training.\n",
    "\n",
    "**Transformation and Imputation**\n",
    "\n",
    "1.  **Apply Logarithmic Transformation:**\n",
    "    * **Features:** `Distance`, `Wind_Gust`\n",
    "    * **Transformation:** `log1p`\n",
    "    * **Rationale:** Address right-skewed distributions and improve model robustness.\n",
    "\n",
    "2.  **Impute Missing Values:**\n",
    "    * **Strategy:** Mean imputation for numeric features, most frequent imputation for categorical features.\n",
    "    * **Rationale:** Maintain data completeness with a simple and effective approach.\n",
    "\n",
    "**Feature Pruning**\n",
    "\n",
    "1.  **Remove Redundant Information:**\n",
    "    * **Action:** Drop columns like city/state names, latitude/longitude, and detailed marketing airline data.\n",
    "    * **Rationale:** Eliminate redundant information that doesn't contribute to prediction accuracy.\n",
    "\n",
    "2.  **Discard Uninformative or Highly Missing Columns:**\n",
    "    * **Action:** Remove columns with significant missing data or those that offer little predictive value.\n",
    "    * **Rationale:** Reduce noise and improve model focus.\n",
    "\n",
    "**Encoding and Categorical**\n",
    "\n",
    "1.  **One-Hot Encoding with Cardinality Limits:**\n",
    "    * **Features:** `OriginAirportID`, `DestAirportID`\n",
    "    * **Encoding:** `OneHotEncoder` with `max_categories=50`.\n",
    "    * **Rationale:** Handle high-cardinality features efficiently while preserving important information.\n",
    "\n",
    "2.  **Full One-Hot Encoding:**\n",
    "    * **Features:** `DayOfWeek`, `Month`, `Operating_Airline`\n",
    "    * **Encoding:** Complete one-hot encoding.\n",
    "    * **Rationale:** Preserve category identity for time- and airline-sensitive predictions.\n",
    "\n",
    "**Dimensionality Reduction**\n",
    "\n",
    "- **Principal Component Analysis (PCA):**\n",
    "    * **Technique:** `PCA(n_components=50)`\n",
    "    * **Rationale:** Address multicollinearity and reduce dimensionality, especially with correlated weather and location data.\n",
    "    * **Benefit:** Improved training efficiency and reduced overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output = \"pandas\")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stratified_random_split(df: pd.DataFrame, target_column: str, test_size: float = 0.1, random_state: int = 42):\n",
    "    \"\"\"\n",
    "    Performs a stratified random train-test split to ensure all classes in \n",
    "    'Flight_Status' are proportionally represented in both sets.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataset containing the target variable.\n",
    "    target_column (str): The column representing the classification target.\n",
    "    test_size (float): The proportion of data to be used as test data.\n",
    "    random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    tuple: (train_df, test_df) DataFrames.\n",
    "    \"\"\"\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, test_size=test_size, stratify=df[target_column], random_state=random_state\n",
    "    )\n",
    "\n",
    "    print(f\"Train size: {len(train_df)} samples\")\n",
    "    print(f\"Test size: {len(test_df)} samples\")\n",
    "\n",
    "    return train_df, test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flight_data = pd.read_parquet(\"data/WEATHER121.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 13184010 samples\n",
      "Test size: 1464890 samples\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data= stratified_random_split(flight_data, target_column=\"Flight_Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_data = train_data.sample(n=100000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=[\"Flight_Status\"])\n",
    "y_train = train_data[\"Flight_Status\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProgressLogger(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A transformer that logs progress through a pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, total_rows, log_interval=0.01, name='Pipeline'):\n",
    "        self.total_rows = total_rows\n",
    "        self.log_interval = log_interval\n",
    "        self.name = name\n",
    "        self.start_time = None\n",
    "        self.last_log_percent = -1\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if self.start_time is None:\n",
    "            self.start_time = time.time()\n",
    "            print(f\"{self.name} processing started on {self.total_rows:,} rows\")\n",
    "        \n",
    "        current_rows = X.shape[0]\n",
    "        percent_complete = current_rows / self.total_rows\n",
    "        \n",
    "        int_percent = int(percent_complete / self.log_interval)\n",
    "        if int_percent > self.last_log_percent:\n",
    "            self.last_log_percent = int_percent\n",
    "            elapsed = time.time() - self.start_time\n",
    "            \n",
    "            percent_done = percent_complete * 100\n",
    "            if percent_complete > 0:\n",
    "                total_est = elapsed / percent_complete\n",
    "                remaining = total_est - elapsed\n",
    "                time_str = f\" - Est. remaining: {remaining:.1f}s\"\n",
    "            else:\n",
    "                time_str = \"\"\n",
    "                \n",
    "            print(f\"{self.name}: {percent_done:.1f}% complete ({current_rows:,}/{self.total_rows:,} rows){time_str}\")\n",
    "        \n",
    "        return X\n",
    "\n",
    "class DelayTrendEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that precomputes a route-based delay trend using week_of_year and top N airports.\n",
    "\n",
    "    Parameters:\n",
    "        date_col (str): Name of the datetime column\n",
    "        origin_col (str): Origin airport column\n",
    "        dest_col (str): Destination airport column\n",
    "        status_col (str): Flight status column for delay signal\n",
    "        output_col (str): Name of the new delay trend feature\n",
    "        top_n_airports (int): Number of top airports to retain by frequency\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 date_col='dep_datetime',\n",
    "                 origin_col='OriginAirportID',\n",
    "                 dest_col='DestAirportID',\n",
    "                 status_col='Flight_Status',\n",
    "                 output_col='Delay_Trend',\n",
    "                 top_n_airports=15):\n",
    "        self.date_col = date_col\n",
    "        self.origin_col = origin_col\n",
    "        self.dest_col = dest_col\n",
    "        self.status_col = status_col\n",
    "        self.output_col = output_col\n",
    "        self.top_n_airports = top_n_airports\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_temp = X.copy()\n",
    "        X_temp[self.date_col] = pd.to_datetime(X_temp[self.date_col])\n",
    "        X_temp['week_of_year'] = X_temp[self.date_col].dt.isocalendar().week\n",
    "\n",
    "        X_temp['Flight_Status'] = y.reset_index(drop=True)\n",
    "        \n",
    "        all_airports = pd.concat([X_temp[self.origin_col], X_temp[self.dest_col]])\n",
    "        top_airports = all_airports.value_counts().head(self.top_n_airports).index\n",
    "        X_temp = X_temp[\n",
    "            X_temp[self.origin_col].isin(top_airports) &\n",
    "            X_temp[self.dest_col].isin(top_airports)\n",
    "        ]\n",
    "\n",
    "        delay_reasons = [\n",
    "            'CarrierDelay', 'WeatherDelay', 'NASDelay',\n",
    "            'SecurityDelay', 'LateAircraftDelay'\n",
    "        ]\n",
    "        X_temp['delay_signal'] = 0\n",
    "        mask = X_temp['Flight_Status'].str.contains('Delay', na=False)\n",
    "        delay_type = X_temp.loc[mask, 'Flight_Status'].str.split(' - ').str[-1]\n",
    "        valid = delay_type.isin(delay_reasons)\n",
    "        X_temp.loc[mask[mask].index[valid], 'delay_signal'] = 1\n",
    "\n",
    "        self.trend_lookup_ = (\n",
    "            X_temp.groupby(['week_of_year', self.origin_col, self.dest_col])['delay_signal']\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .rename(columns={'delay_signal': self.output_col})\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.date_col] = pd.to_datetime(X[self.date_col])\n",
    "        X['week_of_year'] = X[self.date_col].dt.isocalendar().week\n",
    "\n",
    "        X = X.merge(\n",
    "            self.trend_lookup_,\n",
    "            on=['week_of_year', self.origin_col, self.dest_col],\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        X[self.output_col] = X[self.output_col].fillna(0)\n",
    "        return X.drop(columns=['week_of_year'])\n",
    "\n",
    "class SameDayTailReuseEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that creates a feature counting how many times\n",
    "    the same tail number (aircraft) is used on the same day.\n",
    "\n",
    "    Parameters:\n",
    "        datetime_col (str): Column containing full departure datetime\n",
    "        tail_col (str): Column name for tail number\n",
    "        output_col (str): Name of the output column\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 datetime_col='dep_datetime',\n",
    "                 tail_col='Tail_Number',\n",
    "                 output_col='Same_Day_Tail_Reuse'):\n",
    "        self.datetime_col = datetime_col\n",
    "        self.tail_col = tail_col\n",
    "        self.output_col = output_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        X[self.datetime_col] = pd.to_datetime(X[self.datetime_col])\n",
    "\n",
    "        X['dep_date'] = X[self.datetime_col].dt.date\n",
    "\n",
    "        X[self.output_col] = (\n",
    "            X.groupby([self.tail_col, 'dep_date'])[self.tail_col]\n",
    "            .transform('count')\n",
    "            .astype(float)  \n",
    "        )\n",
    "\n",
    "        return X.drop(columns=['dep_date'])\n",
    "\n",
    "    \n",
    "class TurnaroundDelayEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that computes:\n",
    "    - Previous_Flight_Delay: scheduled departure time of previous flight with same tail number on same day\n",
    "    - Turnaround_Time: time between previous arrival and current departure\n",
    "\n",
    "    Parameters:\n",
    "        datetime_col (str): Column with full departure datetime\n",
    "        dep_time_col (str): Column with scheduled departure time (e.g. CRSDepTime)\n",
    "        arr_time_col (str): Column with scheduled arrival time (e.g. CRSArrTime)\n",
    "        tail_col (str): Tail number column\n",
    "        output_prefix (str): Prefix to use for new feature columns\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 datetime_col='dep_datetime',\n",
    "                 dep_time_col='CRSDepTime',\n",
    "                 arr_time_col='CRSArrTime',\n",
    "                 tail_col='Tail_Number',\n",
    "                 output_prefix=''):\n",
    "        self.datetime_col = datetime_col\n",
    "        self.dep_time_col = dep_time_col\n",
    "        self.arr_time_col = arr_time_col\n",
    "        self.tail_col = tail_col\n",
    "        self.output_prefix = output_prefix\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.datetime_col] = pd.to_datetime(X[self.datetime_col])\n",
    "        X['dep_date'] = X[self.datetime_col].dt.date\n",
    "\n",
    "        X = X.sort_values(by=[self.tail_col, 'dep_date', self.dep_time_col])\n",
    "\n",
    "        prev_delay_col = self.output_prefix + 'Previous_Flight_Delay'\n",
    "        turnaround_col = self.output_prefix + 'Turnaround_Time'\n",
    "\n",
    "        X[prev_delay_col] = (\n",
    "            X.groupby([self.tail_col, 'dep_date'])[self.dep_time_col]\n",
    "            .shift(1)\n",
    "        )\n",
    "\n",
    "        X['Previous_Arrival_Time'] = (\n",
    "            X.groupby([self.tail_col, 'dep_date'])[self.arr_time_col]\n",
    "            .shift(1)\n",
    "        )\n",
    "\n",
    "        X[turnaround_col] = self._calculate_turnaround(X[self.dep_time_col], X['Previous_Arrival_Time'])\n",
    "\n",
    "        X[prev_delay_col] = X[prev_delay_col].fillna(0)\n",
    "        X[turnaround_col] = X[turnaround_col].fillna(0)\n",
    "\n",
    "        return X.drop(columns=['dep_date', 'Previous_Arrival_Time'])\n",
    "\n",
    "    def _calculate_turnaround(self, current_dep, previous_arr):\n",
    "        \"\"\"\n",
    "        Applies time difference logic with wrap-around at midnight (2400).\n",
    "        \"\"\"\n",
    "        diff = current_dep - previous_arr\n",
    "        adjusted = diff.mask((~diff.isna()) & (diff < 0), diff + 2400)\n",
    "        return adjusted\n",
    "\n",
    "class SlackTimeEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that calculates slack time as the difference between scheduled\n",
    "    arrival time (CRSArrTime) and scheduled elapsed time (CRSElapsedTime).\n",
    "\n",
    "    Parameters:\n",
    "        arr_col (str): Column name for scheduled arrival time.\n",
    "        elapsed_col (str): Column name for scheduled elapsed time.\n",
    "        output_col (str): Name of the output column to store slack time.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 arr_col='CRSArrTime',\n",
    "                 elapsed_col='CRSElapsedTime',\n",
    "                 output_col='Slack_Time'):\n",
    "        self.arr_col = arr_col\n",
    "        self.elapsed_col = elapsed_col\n",
    "        self.output_col = output_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.output_col] = X[self.arr_col] - X[self.elapsed_col]\n",
    "        return X\n",
    "    \n",
    "    \n",
    "\n",
    "class AgeClipper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that caps aircraft age at a maximum value.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    max_age : float, default=56.9\n",
    "        Maximum value for aircraft age\n",
    "    column_name : str, default='Aircraft_Age'\n",
    "        Name of the column to apply the cap to\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_age=56.9, column_name='Aircraft_Age'):\n",
    "        self.max_age = max_age\n",
    "        self.column_name = column_name\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy() if isinstance(X, pd.DataFrame) else pd.DataFrame(X)\n",
    "        \n",
    "        if self.column_name in X_transformed.columns:\n",
    "            X_transformed[self.column_name] = np.minimum(X_transformed[self.column_name], self.max_age)\n",
    "        \n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X_transformed = X_transformed.values\n",
    "            \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction**\n",
    "\n",
    "1.  **Capture Historical Delay Patterns:**\n",
    "    * **New Feature:** `Delay_Trend`\n",
    "    * **Goal:** Identify recurring delays between specific airport pairs during particular weeks.\n",
    "    * **Implementation:** Aggregate weekly delay data, focusing on the top 15 airports to manage memory and ensure generalizability.\n",
    "    * **Why we thought of this:** Historical delay patterns are strong indicators of future delays.\n",
    "\n",
    "2.  **Assess Aircraft Reuse:**\n",
    "    * **New Feature:** `Same_Day_Tail_Reuse`\n",
    "    * **Goal:** Determine if an aircraft is scheduled for multiple flights on the same day.\n",
    "    * **Why we thought of this:** High reuse can lead to delay propagation.\n",
    "\n",
    "3.  **Calculate Turnaround Time:**\n",
    "    * **New Feature:** `Turnaround_Time`\n",
    "    * **Goal:** Measure the time between an aircraft's arrival and its next scheduled departure.\n",
    "    * **Why we thought of this:** Short turnaround times increase delay vulnerability.\n",
    "\n",
    "4.  **Determine Slack Time:**\n",
    "    * **New Feature:** `Slack_Time`\n",
    "    * **Goal:** Calculate the difference between scheduled arrival and expected travel time.\n",
    "    * **Why we thought of this:** Slack time indicates buffer capacity, which can absorb minor delays.\n",
    "\n",
    "**Outlier**\n",
    "\n",
    "1.  **Handle Extreme Aircraft Age Values:**\n",
    "    * **Feature:** `Aircraft_Age`\n",
    "    * **Issue:**  unrealistic age values (There are hundreds of ages in the thousands)\n",
    "    * **Solution:** Clip outliers to the second highest value (56.9 years). (more reasonable)\n",
    "    * **Why:** Prevent outliers from skewing model training.\n",
    "\n",
    "**Transformation and Imputation**\n",
    "\n",
    "1.  **Apply Logarithmic Transformation:**\n",
    "    * **Features:** `Distance`, `Wind_Gust`\n",
    "    * **Using:** log1p (In case theres 0 values)\n",
    "    * **Why:** Hopefully improve the models performance\n",
    "\n",
    "2.  **Impute Missing Values:**\n",
    "    * **Strategy:** Mean imputation for numeric features, most frequent imputation for categorical features.\n",
    "    * **Why:** Maintain data completeness with a simple and effective approach.\n",
    "\n",
    "**Feature Pruning**\n",
    "\n",
    "1.  **Remove Redundant Information:**\n",
    "    * **Action:** Drop columns like city/state names, latitude/longitude, and detailed marketing airline data.\n",
    "    * **Why:** Eliminate redundant information that doesn't contribute to prediction accuracy.\n",
    "\n",
    "2.  **Discard Uninformative or Highly Missing Columns:**\n",
    "    * **Action:** Remove columns with significant missing data or those that offer little predictive value.\n",
    "    * **Why:** Reduce noise and improve model focus.\n",
    "\n",
    "**Encoding and Categorical**\n",
    "\n",
    "1.  **One-Hot Encoding with Cardinality Limits:**\n",
    "    * **Features:** `OriginAirportID`, `DestAirportID`\n",
    "    * **Encoding:** `OneHotEncoder` with `max_categories=51`.\n",
    "    * **Why:** We made a max of 50 categories (technically 51) so we kept the top 50 out of 300 something columns. 300 columns would be too much.\n",
    "\n",
    "2.  **Full One-Hot Encoding:**\n",
    "    * **Features:** `DayOfWeek`, `Month`, `Operating_Airline`\n",
    "    * **Encoding:** Complete one-hot encoding.\n",
    "    * **Why:** Preserve category identity for time- and airline-sensitive predictions.\n",
    "\n",
    "**Dimensionality Reduction**\n",
    "\n",
    "- **Principal Component Analysis (PCA):**\n",
    "    * **Technique:** `PCA(n_components=50)`\n",
    "    * **Rationale:** Address multicollinearity and reduce dimensionality, especially with correlated weather and location data.\n",
    "    * **Why:** Improved training efficiency and reduced overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;initial_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Starting Pipeline&#x27;, total_rows=13000000)),\n",
       "                (&#x27;delay_trend&#x27;, DelayTrendEncoder()),\n",
       "                (&#x27;trend_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Delay Trend Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;tail_reuse&#x27;, SameDayTailReuseEncoder()),\n",
       "                (&#x27;reuse_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Tail Reuse Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;turnaround_delay&#x27;, T...\n",
       "                                                   &#x27;soil_temperature_0cm&#x27;,\n",
       "                                                   &#x27;rain&#x27;, &#x27;rain_dest_dep_time&#x27;,\n",
       "                                                   &#x27;dew_point_2m_dest_dep_time&#x27;,\n",
       "                                                   &#x27;cloud_cover_mid&#x27;,\n",
       "                                                   &#x27;cloud_cover&#x27;, ...])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;prep_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Feature Prep Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;select&#x27;, PCA(n_components=50, random_state=42)),\n",
       "                (&#x27;final_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Pipeline Complete&#x27;,\n",
       "                                total_rows=13000000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;initial_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Starting Pipeline&#x27;, total_rows=13000000)),\n",
       "                (&#x27;delay_trend&#x27;, DelayTrendEncoder()),\n",
       "                (&#x27;trend_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Delay Trend Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;tail_reuse&#x27;, SameDayTailReuseEncoder()),\n",
       "                (&#x27;reuse_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Tail Reuse Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;turnaround_delay&#x27;, T...\n",
       "                                                   &#x27;soil_temperature_0cm&#x27;,\n",
       "                                                   &#x27;rain&#x27;, &#x27;rain_dest_dep_time&#x27;,\n",
       "                                                   &#x27;dew_point_2m_dest_dep_time&#x27;,\n",
       "                                                   &#x27;cloud_cover_mid&#x27;,\n",
       "                                                   &#x27;cloud_cover&#x27;, ...])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;prep_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Feature Prep Complete&#x27;,\n",
       "                                total_rows=13000000)),\n",
       "                (&#x27;select&#x27;, PCA(n_components=50, random_state=42)),\n",
       "                (&#x27;final_logger&#x27;,\n",
       "                 ProgressLogger(name=&#x27;Pipeline Complete&#x27;,\n",
       "                                total_rows=13000000))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>ProgressLogger</div></div></label><div class=\"sk-toggleable__content \"><pre>ProgressLogger(name=&#x27;Starting Pipeline&#x27;, total_rows=13000000)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>DelayTrendEncoder</div></div></label><div class=\"sk-toggleable__content \"><pre>DelayTrendEncoder()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>ProgressLogger</div></div></label><div class=\"sk-toggleable__content \"><pre>ProgressLogger(name=&#x27;Delay Trend Complete&#x27;, total_rows=13000000)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>SameDayTailReuseEncoder</div></div></label><div class=\"sk-toggleable__content \"><pre>SameDayTailReuseEncoder()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>ProgressLogger</div></div></label><div class=\"sk-toggleable__content \"><pre>ProgressLogger(name=&#x27;Tail Reuse Complete&#x27;, total_rows=13000000)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>TurnaroundDelayEncoder</div></div></label><div class=\"sk-toggleable__content \"><pre>TurnaroundDelayEncoder()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>ProgressLogger</div></div></label><div class=\"sk-toggleable__content \"><pre>ProgressLogger(name=&#x27;Turnaround Delay Complete&#x27;, total_rows=13000000)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>SlackTimeEncoder</div></div></label><div class=\"sk-toggleable__content \"><pre>SlackTimeEncoder()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>ProgressLogger</div></div></label><div class=\"sk-toggleable__content \"><pre>ProgressLogger(name=&#x27;Slack Time Complete&#x27;, total_rows=13000000)</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>feature_prep: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for feature_prep: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(n_jobs=1, remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;numeric&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;age_clipper&#x27;, AgeClipper()),\n",
       "                                                 (&#x27;log1p_distance&#x27;,\n",
       "                                                  ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                    transformers=[(&#x27;log&#x27;,\n",
       "                                                                                   FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;),\n",
       "                                                                                   [&#x27;Distance&#x27;,\n",
       "                                                                                    &#x27;wind_gusts_10m_dest_dep_time&#x27;])],\n",
       "                                                                    verbose_feature_names_out=False))...\n",
       "                                  &#x27;wind_speed_120m_dest_dep_time&#x27;,\n",
       "                                  &#x27;wind_speed_180m_dest_dep_time&#x27;,\n",
       "                                  &#x27;wind_direction_80m_dest_dep_time&#x27;,\n",
       "                                  &#x27;wind_direction_120m_dest_dep_time&#x27;,\n",
       "                                  &#x27;wind_direction_180m_dest_dep_time&#x27;,\n",
       "                                  &#x27;soil_temperature_0cm_dest_dep_time&#x27;,\n",
       "                                  &#x27;soil_temperature_0cm&#x27;, &#x27;rain&#x27;,\n",
       "                                  &#x27;rain_dest_dep_time&#x27;,\n",
       "                                  &#x27;dew_point_2m_dest_dep_time&#x27;,\n",
       "                                  &#x27;cloud_cover_mid&#x27;, &#x27;cloud_cover&#x27;, ...])],\n",
       "                  verbose_feature_names_out=False)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>numeric</div></div></label><div class=\"sk-toggleable__content \"><pre>[&#x27;Distance&#x27;, &#x27;relative_humidity_2m&#x27;, &#x27;temperature_2m&#x27;, &#x27;Aircraft_Age&#x27;, &#x27;temperature_2m_dest_dep_time&#x27;, &#x27;snowfall&#x27;, &#x27;soil_moisture_0_to_1cm&#x27;, &#x27;snowfall_dest_dep_time&#x27;, &#x27;et0_fao_evapotranspiration_dest_dep_time&#x27;, &#x27;surface_pressure_dest_dep_time&#x27;, &#x27;pressure_msl_dest_dep_time&#x27;, &#x27;wind_direction_10m_dest_dep_time&#x27;, &#x27;wind_gusts_10m_dest_dep_time&#x27;, &#x27;CRSElapsedTime&#x27;, &#x27;Slack_Time&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content \"><pre>SimpleImputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>AgeClipper</div></div></label><div class=\"sk-toggleable__content \"><pre>AgeClipper()</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>log1p_distance: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for log1p_distance: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;log&#x27;,\n",
       "                                 FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;),\n",
       "                                 [&#x27;Distance&#x27;, &#x27;wind_gusts_10m_dest_dep_time&#x27;])],\n",
       "                  verbose_feature_names_out=False)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-84\" type=\"checkbox\" ><label for=\"sk-estimator-id-84\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>log</div></div></label><div class=\"sk-toggleable__content \"><pre>[&#x27;Distance&#x27;, &#x27;wind_gusts_10m_dest_dep_time&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-85\" type=\"checkbox\" ><label for=\"sk-estimator-id-85\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>log1p</div><div class=\"caption\">FunctionTransformer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></div></label><div class=\"sk-toggleable__content \"><pre>FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-86\" type=\"checkbox\" ><label for=\"sk-estimator-id-86\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>remainder</div></div></label><div class=\"sk-toggleable__content \"><pre></pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-87\" type=\"checkbox\" ><label for=\"sk-estimator-id-87\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>passthrough</div></div></label><div class=\"sk-toggleable__content \"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-88\" type=\"checkbox\" ><label for=\"sk-estimator-id-88\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content \"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-89\" type=\"checkbox\" ><label for=\"sk-estimator-id-89\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>categorical</div></div></label><div class=\"sk-toggleable__content \"><pre>[&#x27;DayOfWeek&#x27;, &#x27;Month&#x27;, &#x27;OriginAirportID&#x27;, &#x27;DestAirportID&#x27;, &#x27;Is_Holiday_Week&#x27;, &#x27;Operating_Airline &#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-90\" type=\"checkbox\" ><label for=\"sk-estimator-id-90\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>SimpleImputer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></div></label><div class=\"sk-toggleable__content \"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-91\" type=\"checkbox\" ><label for=\"sk-estimator-id-91\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>OHE: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for OHE: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(transformers=[(&#x27;top50&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               max_categories=51,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;OriginAirportID&#x27;, &#x27;DestAirportID&#x27;]),\n",
       "                                (&#x27;OHE&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;DayOfWeek&#x27;, &#x27;Month&#x27;, &#x27;Operating_Airline &#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-92\" type=\"checkbox\" ><label for=\"sk-estimator-id-92\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>top50</div></div></label><div class=\"sk-toggleable__content \"><pre>[&#x27;OriginAirportID&#x27;, &#x27;DestAirportID&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-93\" type=\"checkbox\" ><label for=\"sk-estimator-id-93\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, max_categories=51, sparse_output=False)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-94\" type=\"checkbox\" ><label for=\"sk-estimator-id-94\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>OHE</div></div></label><div class=\"sk-toggleable__content \"><pre>[&#x27;DayOfWeek&#x27;, &#x27;Month&#x27;, &#x27;Operating_Airline &#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-95\" type=\"checkbox\" ><label for=\"sk-estimator-id-95\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-96\" type=\"checkbox\" ><label for=\"sk-estimator-id-96\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>drop</div></div></label><div class=\"sk-toggleable__content \"><pre>[&#x27;Aircraft_Model&#x27;, &#x27;Aircraft_EngineType&#x27;, &#x27;Holiday&#x27;, &#x27;dep_datetime&#x27;, &#x27;Tail_Number&#x27;, &#x27;temperature_120m_dest_dep_time&#x27;, &#x27;temperature_180m_dest_dep_time&#x27;, &#x27;temperature_80m_dest_dep_time&#x27;, &#x27;temperature_180m&#x27;, &#x27;temperature_120m&#x27;, &#x27;temperature_80m&#x27;, &#x27;wind_speed_80m&#x27;, &#x27;wind_speed_120m&#x27;, &#x27;wind_speed_180m&#x27;, &#x27;wind_direction_80m&#x27;, &#x27;wind_direction_120m&#x27;, &#x27;wind_direction_180m&#x27;, &#x27;wind_speed_80m_dest_dep_time&#x27;, &#x27;wind_speed_120m_dest_dep_time&#x27;, &#x27;wind_speed_180m_dest_dep_time&#x27;, &#x27;wind_direction_80m_dest_dep_time&#x27;, &#x27;wind_direction_120m_dest_dep_time&#x27;, &#x27;wind_direction_180m_dest_dep_time&#x27;, &#x27;soil_temperature_0cm_dest_dep_time&#x27;, &#x27;soil_temperature_0cm&#x27;, &#x27;rain&#x27;, &#x27;rain_dest_dep_time&#x27;, &#x27;dew_point_2m_dest_dep_time&#x27;, &#x27;cloud_cover_mid&#x27;, &#x27;cloud_cover&#x27;, &#x27;cloud_cover_mid_dest_dep_time&#x27;, &#x27;cloud_cover_dest_dep_time&#x27;, &#x27;dew_point_2m&#x27;, &#x27;wind_speed_10m&#x27;, &#x27;wind_speed_10m_dest_dep_time&#x27;, &#x27;visibility_dest_dep_time&#x27;, &#x27;visibility&#x27;, &#x27;apparent_temperature&#x27;, &#x27;apparent_temperature_dest_dep_time&#x27;, &#x27;vapour_pressure_deficit&#x27;, &#x27;vapour_pressure_deficit_dest_dep_time&#x27;, &#x27;Flights&#x27;, &#x27;DOT_ID_Operating_Airline&#x27;, &#x27;Flight_Number_Operating_Airline&#x27;, &#x27;Aircraft_Engines&#x27;, &#x27;Aircraft_Seats&#x27;, &#x27;Is_Freighter&#x27;, &#x27;relative_humidity_2m_dest_dep_time&#x27;, &#x27;precipitation&#x27;, &#x27;showers&#x27;, &#x27;snow_depth&#x27;, &#x27;et0_fao_evapotranspiration&#x27;, &#x27;evapotranspiration&#x27;, &#x27;cloud_cover_high&#x27;, &#x27;cloud_cover_low&#x27;, &#x27;surface_pressure&#x27;, &#x27;weather_code&#x27;, &#x27;pressure_msl&#x27;, &#x27;wind_direction_10m&#x27;, &#x27;wind_gusts_10m&#x27;, &#x27;precipitation_dest_dep_time&#x27;, &#x27;showers_dest_dep_time&#x27;, &#x27;snow_depth_dest_dep_time&#x27;, &#x27;soil_moisture_0_to_1cm_dest_dep_time&#x27;, &#x27;evapotranspiration_dest_dep_time&#x27;, &#x27;cloud_cover_high_dest_dep_time&#x27;, &#x27;cloud_cover_low_dest_dep_time&#x27;, &#x27;weather_code_dest_dep_time&#x27;, &#x27;Operated_or_Branded_Code_Share_Partners&#x27;, &#x27;Year&#x27;, &#x27;Quarter&#x27;, &#x27;Marketing_Airline_Network&#x27;, &#x27;DayofMonth&#x27;, &#x27;DOT_ID_Marketing_Airline&#x27;, &#x27;Flight_Number_Marketing_Airline&#x27;, &#x27;OriginAirportSeqID&#x27;, &#x27;OriginCityMarketID&#x27;, &#x27;Origin&#x27;, &#x27;OriginCityName&#x27;, &#x27;OriginState&#x27;, &#x27;OriginStateFips&#x27;, &#x27;OriginStateName&#x27;, &#x27;OriginWac&#x27;, &#x27;DestAirportSeqID&#x27;, &#x27;DestCityMarketID&#x27;, &#x27;Dest&#x27;, &#x27;DestCityName&#x27;, &#x27;DestState&#x27;, &#x27;DestStateFips&#x27;, &#x27;DestStateName&#x27;, &#x27;DestWac&#x27;, &#x27;CRSDepTime&#x27;, &#x27;DepTimeBlk&#x27;, &#x27;CRSArrTime&#x27;, &#x27;ArrTimeBlk&#x27;, &#x27;DistanceGroup&#x27;, &#x27;Duplicate&#x27;, &#x27;Aircraft_Airline&#x27;, &#x27;Aircraft_ModelCode&#x27;, &#x27;Aircraft_Type&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-97\" type=\"checkbox\" ><label for=\"sk-estimator-id-97\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>drop</div></div></label><div class=\"sk-toggleable__content \"><pre>drop</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-98\" type=\"checkbox\" ><label for=\"sk-estimator-id-98\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>remainder</div></div></label><div class=\"sk-toggleable__content \"><pre></pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-99\" type=\"checkbox\" ><label for=\"sk-estimator-id-99\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>passthrough</div></div></label><div class=\"sk-toggleable__content \"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-100\" type=\"checkbox\" ><label for=\"sk-estimator-id-100\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>ProgressLogger</div></div></label><div class=\"sk-toggleable__content \"><pre>ProgressLogger(name=&#x27;Feature Prep Complete&#x27;, total_rows=13000000)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-101\" type=\"checkbox\" ><label for=\"sk-estimator-id-101\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>PCA</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a></div></label><div class=\"sk-toggleable__content \"><pre>PCA(n_components=50, random_state=42)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-102\" type=\"checkbox\" ><label for=\"sk-estimator-id-102\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>ProgressLogger</div></div></label><div class=\"sk-toggleable__content \"><pre>ProgressLogger(name=&#x27;Pipeline Complete&#x27;, total_rows=13000000)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('initial_logger',\n",
       "                 ProgressLogger(name='Starting Pipeline', total_rows=13000000)),\n",
       "                ('delay_trend', DelayTrendEncoder()),\n",
       "                ('trend_logger',\n",
       "                 ProgressLogger(name='Delay Trend Complete',\n",
       "                                total_rows=13000000)),\n",
       "                ('tail_reuse', SameDayTailReuseEncoder()),\n",
       "                ('reuse_logger',\n",
       "                 ProgressLogger(name='Tail Reuse Complete',\n",
       "                                total_rows=13000000)),\n",
       "                ('turnaround_delay', T...\n",
       "                                                   'soil_temperature_0cm',\n",
       "                                                   'rain', 'rain_dest_dep_time',\n",
       "                                                   'dew_point_2m_dest_dep_time',\n",
       "                                                   'cloud_cover_mid',\n",
       "                                                   'cloud_cover', ...])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                ('prep_logger',\n",
       "                 ProgressLogger(name='Feature Prep Complete',\n",
       "                                total_rows=13000000)),\n",
       "                ('select', PCA(n_components=50, random_state=42)),\n",
       "                ('final_logger',\n",
       "                 ProgressLogger(name='Pipeline Complete',\n",
       "                                total_rows=13000000))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "numerical_features = [\n",
    "    'Distance', 'relative_humidity_2m', 'temperature_2m',\n",
    "    'Aircraft_Age', 'temperature_2m_dest_dep_time',\n",
    "    'snowfall', 'soil_moisture_0_to_1cm',\n",
    "    'snowfall_dest_dep_time', \n",
    "    'et0_fao_evapotranspiration_dest_dep_time',\n",
    "    'surface_pressure_dest_dep_time', 'pressure_msl_dest_dep_time',\n",
    "    'wind_direction_10m_dest_dep_time', 'wind_gusts_10m_dest_dep_time', 'CRSElapsedTime', 'Slack_Time'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'DayOfWeek', 'Month',\n",
    "    'OriginAirportID',\n",
    "    'DestAirportID', 'Is_Holiday_Week', 'Operating_Airline '\n",
    "]\n",
    "\n",
    "drop_features = [\n",
    "            'Aircraft_Model', 'Aircraft_EngineType', 'Holiday',\n",
    "            'dep_datetime', 'Tail_Number', 'temperature_120m_dest_dep_time', \n",
    "            'temperature_180m_dest_dep_time', 'temperature_80m_dest_dep_time', 'temperature_180m', \n",
    "            'temperature_120m', 'temperature_80m', 'wind_speed_80m', 'wind_speed_120m',\n",
    "            'wind_speed_180m', 'wind_direction_80m', 'wind_direction_120m', 'wind_direction_180m',\n",
    "            'wind_speed_80m_dest_dep_time', 'wind_speed_120m_dest_dep_time', 'wind_speed_180m_dest_dep_time',\n",
    "            'wind_direction_80m_dest_dep_time', 'wind_direction_120m_dest_dep_time', 'wind_direction_180m_dest_dep_time', \n",
    "            'soil_temperature_0cm_dest_dep_time', 'soil_temperature_0cm', 'rain', 'rain_dest_dep_time', 'dew_point_2m_dest_dep_time', \n",
    "            'cloud_cover_mid', 'cloud_cover', 'cloud_cover_mid_dest_dep_time', 'cloud_cover_dest_dep_time', 'dew_point_2m', \n",
    "            'wind_speed_10m', 'wind_speed_10m_dest_dep_time', 'visibility_dest_dep_time', 'visibility', 'apparent_temperature', \n",
    "            'apparent_temperature_dest_dep_time', 'vapour_pressure_deficit', 'vapour_pressure_deficit_dest_dep_time', 'Flights',\n",
    "            'DOT_ID_Operating_Airline', 'Flight_Number_Operating_Airline', 'Aircraft_Engines', 'Aircraft_Seats', 'Is_Freighter',\n",
    "            'relative_humidity_2m_dest_dep_time', 'precipitation', 'showers', 'snow_depth', 'et0_fao_evapotranspiration',\n",
    "            'evapotranspiration', 'cloud_cover_high', 'cloud_cover_low', 'surface_pressure', 'weather_code', 'pressure_msl', \n",
    "            'wind_direction_10m', 'wind_gusts_10m', 'precipitation_dest_dep_time', 'showers_dest_dep_time', 'snow_depth_dest_dep_time',\n",
    "            'soil_moisture_0_to_1cm_dest_dep_time', 'evapotranspiration_dest_dep_time', 'cloud_cover_high_dest_dep_time',\n",
    "            'cloud_cover_low_dest_dep_time', 'weather_code_dest_dep_time', 'Operated_or_Branded_Code_Share_Partners', 'Year',\n",
    "            'Quarter', 'Marketing_Airline_Network', 'DayofMonth', 'DOT_ID_Marketing_Airline', 'Flight_Number_Marketing_Airline', \n",
    "            'OriginAirportSeqID', 'OriginCityMarketID', 'Origin', 'OriginCityName', 'OriginState', 'OriginStateFips', \n",
    "            'OriginStateName', 'OriginWac', 'DestAirportSeqID', 'DestCityMarketID', 'Dest', 'DestCityName', 'DestState', 'DestStateFips', \n",
    "            'DestStateName', 'DestWac', 'CRSDepTime', 'DepTimeBlk', 'CRSArrTime', 'ArrTimeBlk', 'DistanceGroup', 'Duplicate', \n",
    "            'Aircraft_Airline', 'Aircraft_ModelCode', 'Aircraft_Type'\n",
    "        ]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('age_clipper', AgeClipper(max_age=56.9, column_name='Aircraft_Age')),\n",
    "    ('log1p_distance', ColumnTransformer([\n",
    "        ('log', FunctionTransformer(np.log1p), ['Distance', 'wind_gusts_10m_dest_dep_time'])\n",
    "    ], remainder='passthrough', verbose_feature_names_out=False)), \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('OHE', ColumnTransformer([\n",
    "        ('top50', OneHotEncoder(handle_unknown='ignore', sparse_output=False, max_categories=51), ['OriginAirportID', 'DestAirportID']),\n",
    "        ('OHE' , OneHotEncoder(handle_unknown='ignore', sparse_output=False), ['DayOfWeek', 'Month', 'Operating_Airline '])\n",
    "    ]))\n",
    "])\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "    ('initial_logger', ProgressLogger(total_rows=13000000, name='Starting Pipeline')),\n",
    "    \n",
    "    ('delay_trend', DelayTrendEncoder(\n",
    "        date_col='dep_datetime',\n",
    "        origin_col='OriginAirportID',\n",
    "        dest_col='DestAirportID',\n",
    "        status_col='Flight_Status',\n",
    "        output_col='Delay_Trend',\n",
    "        top_n_airports=15\n",
    "    )),\n",
    "    \n",
    "    ('trend_logger', ProgressLogger(total_rows=13000000, name='Delay Trend Complete')),\n",
    "    \n",
    "    ('tail_reuse', SameDayTailReuseEncoder(\n",
    "        datetime_col='dep_datetime',\n",
    "        tail_col='Tail_Number',\n",
    "        output_col='Same_Day_Tail_Reuse'\n",
    "    )),\n",
    "    \n",
    "    ('reuse_logger', ProgressLogger(total_rows=13000000, name='Tail Reuse Complete')),\n",
    "    \n",
    "    ('turnaround_delay', TurnaroundDelayEncoder(\n",
    "        datetime_col='dep_datetime',\n",
    "        dep_time_col='CRSDepTime',\n",
    "        arr_time_col='CRSArrTime',\n",
    "        tail_col='Tail_Number',\n",
    "        output_prefix=''\n",
    "    )),\n",
    "    \n",
    "    ('turnaround_logger', ProgressLogger(total_rows=13000000, name='Turnaround Delay Complete')),\n",
    "    \n",
    "    ('slack_time', SlackTimeEncoder(\n",
    "        arr_col='CRSArrTime',\n",
    "        elapsed_col='CRSElapsedTime',\n",
    "        output_col='Slack_Time'\n",
    "    )),\n",
    "    \n",
    "    ('slack_logger', ProgressLogger(total_rows=13000000, name='Slack Time Complete')),\n",
    "    \n",
    "    ('feature_prep', ColumnTransformer([\n",
    "        ('numeric', numeric_transformer, numerical_features),\n",
    "        ('categorical', categorical_transformer, categorical_features),\n",
    "        ('drop', 'drop', drop_features)\n",
    "    ], remainder='passthrough', verbose_feature_names_out=False, n_jobs=1)),\n",
    "    \n",
    "    ('prep_logger', ProgressLogger(total_rows=13000000, name='Feature Prep Complete')),\n",
    "    ('select', PCA(\n",
    "        n_components=50,\n",
    "        random_state=42,\n",
    "    )),\n",
    "    ('final_logger', ProgressLogger(total_rows=13000000, name='Pipeline Complete'))\n",
    "])\n",
    "# so that I dont forget, dep_datetime is dropped because of redundancy\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Pipeline processing started on 13,000,000 rows\n",
      "Starting Pipeline: 101.4% complete (13,184,010/13,000,000 rows) - Est. remaining: -0.0s\n",
      "Delay Trend Complete processing started on 13,000,000 rows\n",
      "Delay Trend Complete: 101.4% complete (13,184,010/13,000,000 rows) - Est. remaining: 0.0s\n",
      "Tail Reuse Complete processing started on 13,000,000 rows\n",
      "Tail Reuse Complete: 101.4% complete (13,184,010/13,000,000 rows) - Est. remaining: 0.0s\n",
      "Turnaround Delay Complete processing started on 13,000,000 rows\n",
      "Turnaround Delay Complete: 101.4% complete (13,184,010/13,000,000 rows) - Est. remaining: -0.0s\n",
      "Slack Time Complete processing started on 13,000,000 rows\n",
      "Slack Time Complete: 101.4% complete (13,184,010/13,000,000 rows) - Est. remaining: -0.0s\n",
      "Feature Prep Complete processing started on 13,000,000 rows\n",
      "Feature Prep Complete: 101.4% complete (13,184,010/13,000,000 rows) - Est. remaining: -0.0s\n",
      "Pipeline Complete processing started on 13,000,000 rows\n",
      "Pipeline Complete: 101.4% complete (13,184,010/13,000,000 rows) - Est. remaining: 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pca0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca9",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca11",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca12",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca13",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca14",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca15",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca16",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca17",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca18",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca19",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca21",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca22",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca23",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca24",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca25",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca26",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca27",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca28",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca29",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca30",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca31",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca32",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca33",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca34",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca35",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca36",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca37",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca38",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca39",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca40",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca41",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca42",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca43",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca44",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca45",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca46",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca47",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca48",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pca49",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "fec6729e-aa01-4ccb-b4d9-d6d1bedbd658",
       "rows": [
        [
         "237129",
         "-854.8338383966131",
         "-22.350535231769257",
         "-2.0763698357837326",
         "0.4402973283327545",
         "0.1673370766164503",
         "-0.5728126428501548",
         "-1.7377088645074619",
         "1.9393589905290973",
         "0.5989968078717176",
         "-0.055868625665144396",
         "-0.1376697569914",
         "-0.5482539322073241",
         "-0.5423116081996116",
         "0.29861292726392263",
         "2.0883482531864788",
         "0.8489270724351279",
         "-0.6700516003071155",
         "0.047257037055592824",
         "0.21208814256142686",
         "-0.1287729601280972",
         "-0.051729608159173365",
         "-0.34299527646034356",
         "0.7482617645365806",
         "-0.34546799859333105",
         "-0.041718458473323575",
         "0.1325282735432574",
         "-0.14206428965376333",
         "0.02207051849134814",
         "-0.05956772653593088",
         "0.017391473545296614",
         "-0.06589513614758839",
         "-0.026876605530564555",
         "0.02162175608523494",
         "-0.05033120419871863",
         "0.10227065124506741",
         "-0.06684357271330617",
         "0.13047549261678285",
         "0.5519338509627822",
         "0.5705528767780098",
         "-0.21032103273784886",
         "-0.25709751938913405",
         "0.002678343636239931",
         "0.17358914744532375",
         "-0.2738640329768113",
         "-0.09128578298664436",
         "0.03998157779854447",
         "-0.003104247916608677",
         "-0.021177196588573748",
         "-0.032929311812437925",
         "0.007209950221961279"
        ],
        [
         "4084368",
         "-854.8341408255516",
         "-22.338888107849105",
         "-1.0701684441991075",
         "-0.9280083187317544",
         "0.10907191911475506",
         "0.6527652116403269",
         "1.616178995986075",
         "-0.33874370725672825",
         "0.23995742931708858",
         "-0.4152724396297959",
         "-0.021180237897471754",
         "-0.5143266523211273",
         "1.0268360756719352",
         "-0.05146757106702049",
         "0.16135985499558952",
         "-0.7470068693227284",
         "0.014852213944453739",
         "-0.8618471971621791",
         "-0.25089496545941525",
         "-0.11913467670760035",
         "-0.13381251394180851",
         "-0.5645264252488092",
         "-0.6420906996142971",
         "-0.42473077315596575",
         "-0.07578750118244543",
         "-0.1971305516252444",
         "-0.17677187031915895",
         "-0.3529917260508072",
         "-0.31517677001967964",
         "-0.04022304744682017",
         "-0.038653622377356915",
         "0.016542513747212648",
         "-0.03755077732589927",
         "-0.05435456153370725",
         "0.05514374687273823",
         "-0.03969212968140218",
         "-0.11610982176776216",
         "0.3006077384016993",
         "-0.40533186631510776",
         "0.7240858230270034",
         "-0.12080066524392366",
         "-0.010669912343061486",
         "0.046517067897870405",
         "-0.18414265293395615",
         "-0.03553268520510385",
         "-0.030639698330451562",
         "0.08165067927811151",
         "-0.09620869866478926",
         "-0.10667687154665255",
         "0.052260464239723976"
        ],
        [
         "1029548",
         "147.7130962731709",
         "-77.10884594594401",
         "-2.508873209341528",
         "0.2190405476920344",
         "0.18327052222932777",
         "-0.052361810548699206",
         "-1.468814516385229",
         "0.8919226234896789",
         "0.6710559750567457",
         "-0.2969540387584812",
         "-0.029718904473474",
         "-1.0963537907339405",
         "-0.7706530527485846",
         "-0.6394871180845068",
         "0.5457670969283291",
         "-0.418539964918924",
         "-0.4631751351581781",
         "0.5303436434815064",
         "0.03567495164504498",
         "-0.09831637391428051",
         "-0.16252969536308665",
         "-0.5703276560519812",
         "-0.6559887843199549",
         "-0.407678537932202",
         "-0.07888655693519703",
         "-0.17433144362955655",
         "-0.14063486333358385",
         "-0.34858981450116644",
         "-0.346865723785845",
         "-0.048655295976298404",
         "-0.07134071596445846",
         "-0.003488812167580085",
         "-0.006502414086571463",
         "-0.04487737858446323",
         "0.046852529956988284",
         "-0.06922200434928748",
         "-0.12584828198861603",
         "0.3348638829330362",
         "-0.39016250543407927",
         "0.7231940336908926",
         "-0.13480937298149587",
         "0.04366054668328579",
         "0.05749485058752395",
         "-0.17364710618792975",
         "-0.040443084309800745",
         "0.051205226567634966",
         "0.059454229803889584",
         "-0.13328374491004077",
         "0.035109907362572454",
         "0.01781183619735273"
        ],
        [
         "11163145",
         "-854.8310509805441",
         "-22.315751014514106",
         "0.932171283465375",
         "-1.247212616883599",
         "0.26462765927174076",
         "0.3784293138182413",
         "1.0928360891320632",
         "-0.7470418927962756",
         "-0.01922471551138391",
         "-0.3763633192981251",
         "-0.005954412065997082",
         "-0.3754360435122589",
         "-0.1563677436382912",
         "0.35474668999185327",
         "-0.05044856961845129",
         "-0.307445434804546",
         "-0.06076739811742987",
         "-0.8078865253186571",
         "-0.26002807120841437",
         "-0.2959903736335875",
         "-0.4425262576432014",
         "0.6955108220439964",
         "-0.10520599819030639",
         "-0.35045078975653526",
         "-0.06912080084757216",
         "-0.2356728196876724",
         "-0.16217053138443746",
         "-0.36908036317780757",
         "-0.3738253689766641",
         "-0.024298082764394335",
         "-0.02688598930766975",
         "-0.015455276171139492",
         "-0.058525066821513705",
         "-0.08188630210594879",
         "0.08033498650541748",
         "-0.05261378339107495",
         "-0.10899173491490269",
         "0.3102706340270351",
         "-0.40362027038447096",
         "0.7455793503860305",
         "-0.12343034062509406",
         "-0.017222571797714956",
         "0.04985067947180092",
         "-0.20499771809752731",
         "-0.022656455564652622",
         "-0.019726627534080575",
         "0.06500227270782698",
         "-0.08958035854629531",
         "-0.1177941051369687",
         "0.048885107761481965"
        ],
        [
         "12079249",
         "-119.47668478150717",
         "-38.25222137762159",
         "-0.40323374351709695",
         "-0.08871337408960212",
         "0.2738556634297831",
         "0.8855717678986194",
         "-0.9064571571423776",
         "-0.7896044995139881",
         "0.5868948206171256",
         "-0.5643275300002387",
         "0.17397481906749063",
         "-1.2935120953927035",
         "-1.0458072886955863",
         "-0.4934076582863759",
         "0.8003154434708418",
         "-0.3779580173766496",
         "-0.7313102120843743",
         "0.48823567386297057",
         "0.05533826128052301",
         "-0.27229830648260944",
         "-0.4483546735240076",
         "0.6966109822245633",
         "-0.10724264522255898",
         "-0.3392250109283823",
         "-0.06242320538261803",
         "-0.19525726230785606",
         "-0.13783698069252093",
         "-0.35829283511537535",
         "-0.37829288002280836",
         "-0.03407745461620625",
         "-0.05309514202336112",
         "-0.025849956579598724",
         "-0.046370761918956775",
         "-0.08751090395209797",
         "0.07209567701859161",
         "-0.07366144988364033",
         "-0.10935680651821067",
         "0.31496470266360665",
         "-0.39123108768481796",
         "0.759849217087209",
         "-0.1271143150960648",
         "0.031211650514209918",
         "0.06348041922237133",
         "-0.20238871606595085",
         "-0.00783496168047243",
         "0.036338284382433673",
         "0.045205912757238974",
         "-0.12933947363619844",
         "0.02834931837873241",
         "0.012827773022341015"
        ],
        [
         "9306146",
         "187.48598805928737",
         "-123.28296044593627",
         "-0.05948530327975554",
         "0.06878391819775576",
         "0.6811454729865227",
         "0.1680416161304445",
         "1.291633240177356",
         "-0.3990289138093414",
         "-0.04734450282553018",
         "-0.14829565296617703",
         "0.14176718223159396",
         "0.12828795451379388",
         "0.6666162472868067",
         "0.4340130099217076",
         "-0.5034260042672759",
         "-1.1556573212467114",
         "0.08357400512956581",
         "-0.1564688636686153",
         "0.01778267515787161",
         "-0.11760539177862996",
         "-0.5015995041767671",
         "0.7051192024339376",
         "-0.09972879813578646",
         "-0.2760773172316072",
         "-0.02801595477501197",
         "0.18140852784036526",
         "-0.056078934488499994",
         "-0.0011983506531583754",
         "-0.24563414800558311",
         "-0.022339486129094786",
         "-0.028405130569509336",
         "-0.039037966608675215",
         "-0.06130415972097903",
         "-0.02880596470717906",
         "0.11482903533016497",
         "-0.022626953350421856",
         "0.04750393079132875",
         "0.32161220838025706",
         "-0.4327895083595268",
         "0.7043700239694312",
         "-0.2722776231377342",
         "0.019567565701362102",
         "0.16612999855234797",
         "-0.2702955992477438",
         "-0.10614005561708971",
         "-0.036056334074393015",
         "0.10582431236028726",
         "-0.07203123342662099",
         "-0.06106135944275165",
         "0.058625998774766284"
        ],
        [
         "11497403",
         "501.99454817526066",
         "-128.57589716591212",
         "-0.6478285045867547",
         "-0.20257292932597293",
         "0.7941793599153708",
         "0.841837287149088",
         "-0.7065868348846446",
         "-0.8337020336839138",
         "0.5468855956257825",
         "-0.5925871834195289",
         "0.2434944018489533",
         "-1.16706431441385",
         "-0.9605839854512106",
         "-0.10268774866621833",
         "1.5571519523858657",
         "-0.15854886461325648",
         "-0.7739896555732021",
         "-0.08437895456858274",
         "0.11448118071847646",
         "-0.12708773944592527",
         "-0.4802070355748008",
         "0.7084265160753644",
         "-0.10193195690001142",
         "-0.25630841953923295",
         "-0.014190994736292553",
         "0.2422308431207892",
         "-0.045383148944581564",
         "0.01464016324564707",
         "-0.19505844761060684",
         "-0.04569264222542725",
         "-0.07570495439170702",
         "-0.055350818684255704",
         "-0.03791472879114518",
         "-0.06091207917722514",
         "0.1026613504377424",
         "-0.07627422322708059",
         "0.07353068789150047",
         "0.253622912804434",
         "-0.3889248764927168",
         "0.7875336108538488",
         "-0.258534931452601",
         "-0.013413617140283059",
         "0.16393841132490466",
         "-0.25951480119609405",
         "-0.02503590487466254",
         "-0.005602497917544616",
         "0.029389560399504397",
         "-0.05003918262711681",
         "-0.0034595278299400425",
         "0.01715905569362774"
        ],
        [
         "11050909",
         "-854.8299634581351",
         "-22.32741642366042",
         "-0.07274533843799524",
         "0.4653250829697926",
         "-0.46380277119665936",
         "-1.9272303384768386",
         "0.40691638930255053",
         "1.0662477385323097",
         "0.40448942428812884",
         "-0.5609669122661661",
         "-0.36429826137360577",
         "-1.3828900628914862",
         "0.06724274717847428",
         "1.2796083719482403",
         "-0.41722436999506196",
         "-0.30462122057842833",
         "0.2961051132687211",
         "-0.7128674967464926",
         "-0.27761789542511456",
         "-0.21764609645727928",
         "-0.07210319816424175",
         "-0.35337208191941666",
         "0.735496189640094",
         "-0.44494753638665413",
         "-0.09863114684009816",
         "-0.24088382883614556",
         "-0.1688438771356994",
         "-0.32754985136756676",
         "-0.30722195416327847",
         "-0.0026491895323705822",
         "-0.05616015601926305",
         "-0.0454983080759012",
         "-0.03050251559627587",
         "-0.08326247359983818",
         "0.04686754220682453",
         "-0.04920249915492284",
         "-0.11819713790154968",
         "0.3828763349670806",
         "-0.44544518094861657",
         "0.6685283379284365",
         "-0.13501790126149024",
         "-0.021306976523312558",
         "0.04809462546007967",
         "-0.20594808791716224",
         "-0.10113334721837855",
         "0.010965056476086714",
         "0.08286107970847752",
         "-0.10234179634144652",
         "-0.1339114500889995",
         "0.06458003354060121"
        ],
        [
         "12404073",
         "374.33455916154435",
         "-110.03380545544728",
         "-1.5934708786135046",
         "0.43627514588156835",
         "-0.6659890544312783",
         "-0.6991133907263813",
         "0.3277594561408111",
         "-1.1421026205811973",
         "0.01574085100973155",
         "-0.47949022011203896",
         "0.022172427595160492",
         "-0.9748909655490305",
         "-0.44163148517885176",
         "0.3148759263871246",
         "0.3615637698225821",
         "-0.5439985571035274",
         "-1.034330489271209",
         "-0.07570391379452136",
         "-0.29022945979158454",
         "-0.3689383595457352",
         "-0.0199424596211246",
         "-0.34833728184057167",
         "0.7305971364443798",
         "-0.47579220380322595",
         "-0.11147739707805146",
         "-0.5109593078942675",
         "-0.2062633647003063",
         "-0.5981103249666927",
         "-0.3990512969351113",
         "0.00839690304374241",
         "-0.032248441446166315",
         "-0.029979129161894495",
         "-0.06728433631399457",
         "-0.13043421125019428",
         "0.01694944726624952",
         "-0.07902361254909987",
         "-0.3742976535962498",
         "0.3523330921881268",
         "-0.47789910073142605",
         "0.6706812276993642",
         "0.055923327108578114",
         "-0.017477297453535393",
         "0.02583777773769154",
         "-0.27639792501872346",
         "-0.00953065449148767",
         "0.018922071636679416",
         "0.04170062774199824",
         "-0.16608290471521422",
         "-0.08880935128530201",
         "-0.030414537022694636"
        ],
        [
         "6852300",
         "672.2055779380396",
         "-153.32600963289028",
         "-1.7113103684150963",
         "-0.14986495822751578",
         "-0.4103509612766969",
         "-1.3088485873318314",
         "-0.4024881635377332",
         "0.3354165048965297",
         "-0.02340785968786452",
         "-0.22839594933447419",
         "-0.200836060662667",
         "-0.6150371801296544",
         "-0.5902996875215345",
         "2.0811714233569893",
         "-1.1574270900947785",
         "-0.08746497525087077",
         "0.2403601081029374",
         "0.20309391092601262",
         "-0.41267999973058556",
         "-0.3530250771553278",
         "-0.053070032240445486",
         "-0.3610559553101053",
         "0.7222926888393154",
         "-0.4800331931781901",
         "-0.13447115611646882",
         "-0.6678343164600302",
         "-0.21985670366672205",
         "-0.6015892311673434",
         "-0.44356696580087696",
         "0.01187206234966786",
         "-0.036428938495141276",
         "-0.021785289841736107",
         "-0.05458291484859631",
         "-0.11966550907401552",
         "0.01768336967819557",
         "-0.04077765347317161",
         "-0.35231863597304075",
         "0.419864502761341",
         "-0.38654202815771166",
         "0.6969225480953751",
         "0.011135552118659131",
         "0.012494450287598394",
         "-0.00642252869575638",
         "-0.22262952919495058",
         "-0.046052097169446235",
         "0.03957100613790831",
         "0.09394842473224839",
         "-0.15160949774445923",
         "-0.12423606422270898",
         "-0.007225074666608818"
        ],
        [
         "6627427",
         "-854.8358419883687",
         "-22.338685607108058",
         "-1.0715889339020714",
         "-1.0320031166095216",
         "1.645162300050838",
         "0.4639244301461015",
         "-0.6430035760753022",
         "-0.19473590695190984",
         "0.09453555502672638",
         "-0.26679825092100223",
         "0.39367671349302275",
         "-0.22317881040126164",
         "-0.6686549753729554",
         "-0.6973026362259673",
         "0.9443482464642028",
         "-0.298697515171065",
         "-0.8373947042598804",
         "-0.1611288654581038",
         "-0.41784795976835365",
         "-0.19220685237942725",
         "0.9152235472135251",
         "0.246189469423248",
         "-0.1426288130550562",
         "-0.3952956275716789",
         "-0.12303375115591961",
         "-0.7984614323829718",
         "-0.31412921747579253",
         "-0.6763364390805703",
         "-0.06636242358929242",
         "0.028258907697663576",
         "-0.007330178016384971",
         "0.03506101006143235",
         "-0.040876490182316066",
         "-0.10334382542470955",
         "-0.02073569968305044",
         "-0.04616434716375793",
         "-0.3704214719265679",
         "0.2765192120070942",
         "-0.3828307407874151",
         "0.8051963879239892",
         "0.0773456395674838",
         "0.010655806003283138",
         "-0.01101423960889343",
         "-0.22278440355669193",
         "0.10500562153444955",
         "-0.0063914628500444486",
         "0.05936346712155876",
         "-0.1263705207560674",
         "-0.025818047792246626",
         "-0.03471674258382016"
        ],
        [
         "7844955",
         "-139.27383723299374",
         "-35.39797308483464",
         "-2.3962703847549713",
         "-1.3500245761494756",
         "1.4513408716297205",
         "-2.071319638996538",
         "1.724737126013268",
         "-0.24935577620620414",
         "-0.7329284260465417",
         "-0.27049195698544537",
         "0.09485415537338948",
         "0.24459528203924263",
         "-0.13065917290587414",
         "1.2333293455490768",
         "-0.4627807996347898",
         "-0.9038729940874703",
         "-0.20312428759777132",
         "-0.0447380518230273",
         "-0.33153738650330294",
         "-0.1374864517341638",
         "0.8733002309607893",
         "0.2532132533634294",
         "-0.13886364562390982",
         "-0.4096226375236618",
         "-0.13468522381268844",
         "-0.7998480674665176",
         "-0.247461957860003",
         "-0.7925689320776779",
         "-0.44648273792202364",
         "0.040639978728578",
         "0.006011783172293813",
         "0.009670235836821521",
         "-0.08741208172438292",
         "-0.10338239691425553",
         "0.02385314074429811",
         "-0.049728438411066",
         "-0.3264726438900398",
         "0.33074351487177456",
         "-0.5146928177185062",
         "0.6525865323598933",
         "0.036713210991216993",
         "0.0010753718060404474",
         "-0.045834245126134876",
         "-0.24267821928432323",
         "0.011342488192240416",
         "-0.007081259469873483",
         "0.09304456922379872",
         "-0.10230142061188272",
         "-0.10831931144171665",
         "-0.01807203549444971"
        ],
        [
         "12796004",
         "-854.8369074526091",
         "-22.350578972912007",
         "-2.0698780696206676",
         "-0.7340035079608443",
         "0.472653776772233",
         "1.108357761230046",
         "-0.8905809158653774",
         "-0.43533293256089595",
         "0.5124705431452317",
         "-0.4146751467049554",
         "0.19697380694917807",
         "-0.9029667490327931",
         "-0.7213133640168723",
         "-0.35587929927745376",
         "0.8921062608666128",
         "-0.417305737276213",
         "-0.7900753980654468",
         "-0.22026537670492075",
         "-0.29244289559719355",
         "-0.29769464438271476",
         "0.05880804815164871",
         "-0.06125737335191711",
         "-0.027954379370023076",
         "0.4840140400067752",
         "-0.7114821117003395",
         "-0.6714094360307385",
         "-0.34876146550720144",
         "-0.785911085676517",
         "-0.4276841089525116",
         "0.0014814303167420282",
         "-0.04771519420785453",
         "0.043311819739630525",
         "-0.053837899541603514",
         "-0.08199404421257614",
         "0.014744541321839132",
         "-0.09433105818824912",
         "-0.3187518053220512",
         "0.30679143179610974",
         "-0.37824492577636104",
         "0.7923430035144676",
         "0.008121666150579493",
         "0.018154383242839623",
         "-0.013162684335392028",
         "-0.20529390779359144",
         "0.06038471610152009",
         "0.021833739941744132",
         "0.08278184098182806",
         "-0.1464422680192561",
         "-0.03346873948954361",
         "-0.010477158294572766"
        ],
        [
         "5418778",
         "-854.8349116983169",
         "-22.338882242806047",
         "-1.0689947690681532",
         "-0.49669910281024354",
         "0.572391614305346",
         "-0.10686259449757267",
         "-0.5235626773668944",
         "0.31307119819020873",
         "0.44592245463856683",
         "-0.36461898443571067",
         "-0.062067948360666064",
         "-0.8495973236823415",
         "-1.4950942690193643",
         "-0.5591345512716972",
         "1.238844072229404",
         "-0.5859682739143397",
         "-0.8891331854790739",
         "-0.29502514211377795",
         "-0.2467804412238615",
         "-0.488058999652661",
         "-0.39728620960740824",
         "0.6847547328980511",
         "-0.13175195897766565",
         "-0.4197917443113996",
         "-0.11320406530940208",
         "-0.629622732686922",
         "-0.24706534214066297",
         "-0.7793430805540512",
         "-0.4822134381619362",
         "-0.02580390633356812",
         "-0.039986512688349234",
         "-0.018063828773953114",
         "-0.03550689244889255",
         "-0.105745762528197",
         "0.04314872373796399",
         "-0.11158740658605698",
         "-0.2945323584281418",
         "0.31825165698230107",
         "-0.4239542035640872",
         "0.7449614321818869",
         "0.03095406769481271",
         "0.010161866023288172",
         "-0.013894890046570726",
         "-0.2314729167979073",
         "0.043431967930712065",
         "0.029784558405063638",
         "0.0718095090973083",
         "-0.1626774446033292",
         "-0.025563772521600345",
         "0.007938603584077084"
        ],
        [
         "8310986",
         "-114.53262383745266",
         "-38.99406773936507",
         "-2.408967518355995",
         "-0.7123378142322064",
         "1.1005548668546017",
         "0.5023615812711448",
         "1.2329745474491858",
         "0.7267227814272887",
         "0.3850738206833648",
         "-0.3427013952192165",
         "0.03330160972094367",
         "-0.33593026187985553",
         "1.1072751274791108",
         "-0.6210560136034615",
         "-0.42029675484281603",
         "-0.41334036927016615",
         "0.5865184060791598",
         "-0.012680283342321703",
         "-0.41595631140507544",
         "-0.5083514113100552",
         "-0.38008566957502965",
         "0.6650295895520287",
         "-0.12347241980980293",
         "-0.4200772612442911",
         "-0.12007724069096645",
         "-0.8275402810857336",
         "-0.31240132357364986",
         "-0.6842239362070552",
         "-0.3077323124213085",
         "-0.011119604139487496",
         "0.027524967999058958",
         "0.0627614531557518",
         "-0.023171662236622065",
         "-0.092790066708174",
         "0.02510860148171499",
         "-0.019168091927396023",
         "-0.2921159411816032",
         "0.3706681486291643",
         "-0.3517944822987956",
         "0.7653739635932321",
         "0.01934174676462541",
         "0.03615577393137663",
         "-0.021107709575444056",
         "-0.2051079640439727",
         "-0.013977589217783103",
         "0.006045539971894229",
         "0.11476079264087397",
         "-0.16537001767998552",
         "-0.08591294124539257",
         "0.010610064304140843"
        ],
        [
         "1000977",
         "-854.8350475850882",
         "-22.338716983993855",
         "-1.074130908977596",
         "-0.6360676797256252",
         "1.632015068083637",
         "-0.09607414607692298",
         "-1.778706907452549",
         "0.9837718584480586",
         "0.12901616957332207",
         "0.010760821677002277",
         "0.36853397398057874",
         "0.0006908492772131902",
         "-0.7523624998825837",
         "-1.2624741380957647",
         "1.699069133064084",
         "0.12020063307863713",
         "-0.7182631452708619",
         "-0.11000978981757631",
         "-0.4230888525223998",
         "-0.47686936842414707",
         "0.117416172436204",
         "-0.05886279605078641",
         "-0.06003509820038274",
         "-0.05210020260727764",
         "-0.06738749183643866",
         "-1.0784365174238655",
         "0.6620623127213568",
         "-0.6192059176813834",
         "-0.033596185792751206",
         "0.0006221752161857464",
         "0.03552116709960055",
         "0.013359878314859675",
         "0.019618975050369955",
         "-0.08348642060853526",
         "-0.02064783621177143",
         "-0.07850918323916725",
         "-0.3803509903341772",
         "0.30901755172028333",
         "-0.3406720221193865",
         "0.8233320953337796",
         "0.04263686755263854",
         "0.026053906442061497",
         "-0.0025939657815268052",
         "-0.21727428905610374",
         "0.10297326575439199",
         "0.0027716866389413328",
         "0.05127414808914191",
         "-0.13536972029386848",
         "-0.018424447287818668",
         "-0.03647724721001668"
        ],
        [
         "6852584",
         "42.999285519900354",
         "-102.30704619803059",
         "-2.006541002602118",
         "-0.6303746860558924",
         "1.6528017484351785",
         "0.344188726730434",
         "0.6469804848889943",
         "0.7328450278183235",
         "0.45860088841408675",
         "-0.3255356081423571",
         "0.1693301079086209",
         "-0.45166917811141155",
         "0.6107700318462389",
         "-0.24357908716659837",
         "0.13898529095585702",
         "-1.592702237936543",
         "0.9897105197671413",
         "-0.19621540464691098",
         "-0.5095124617733674",
         "-0.4017389921005116",
         "0.11085389471486073",
         "-0.06321889954614944",
         "-0.04310355149365861",
         "-0.046302468262033436",
         "-0.06060817760216716",
         "-1.0385692712761023",
         "0.7022124583023803",
         "-0.6867566661998059",
         "-0.3726646261484807",
         "0.0035188940299542308",
         "0.013892208043942823",
         "0.022687661115964732",
         "0.010154464841316374",
         "-0.0866950796440728",
         "-0.013360447977713",
         "-0.04731374451624541",
         "-0.3016157123333531",
         "0.3522735495373286",
         "-0.2921269054416876",
         "0.8367508852676916",
         "-0.04496272298980791",
         "0.050386814169400086",
         "-0.027093901865544917",
         "-0.18854660041826857",
         "0.0354719308524878",
         "-0.02926008114091845",
         "0.18804426510291175",
         "-0.20978453685421308",
         "-0.04773916233216795",
         "0.06260748179173181"
        ],
        [
         "7604163",
         "-854.8297712710217",
         "-22.316227392593337",
         "0.9353146167955684",
         "0.34141878687519595",
         "-1.1609065666035427",
         "-0.059700889082007616",
         "-0.6020870764766328",
         "-0.4494844936207764",
         "0.17286972693433783",
         "-0.14211051638188998",
         "-0.21180920991551114",
         "-0.6906786275475338",
         "-1.7023477523305115",
         "-0.16649141741128926",
         "0.7119202456276924",
         "-0.4238527228196344",
         "-0.23842110146314494",
         "-0.2192941018110077",
         "-0.3709480414899398",
         "-0.38581507455044817",
         "-0.004529887020663707",
         "-0.3626583631222063",
         "0.729567235728886",
         "-0.46781643915823984",
         "-0.11262471921870268",
         "-0.513264127995013",
         "-0.24199646639017877",
         "-0.5845297475852772",
         "-0.3778130079405185",
         "0.003565505675779267",
         "-0.05456559779673735",
         "-0.012178616217869576",
         "-0.013332250066088912",
         "-0.11905308903839015",
         "-0.009891342935811847",
         "-0.07433140128703909",
         "-0.35047712656654295",
         "0.29725836506279874",
         "-0.343662610830078",
         "0.8050246901842677",
         "0.020322109663777982",
         "0.01199489311314909",
         "0.06349151673351336",
         "-0.279879984811883",
         "-0.0020594411955165426",
         "0.01051696407575463",
         "0.07230221178122385",
         "-0.22926513636065007",
         "-0.05494427255082909",
         "0.02570307588635033"
        ],
        [
         "6944753",
         "-139.26856664493175",
         "-35.37549167938359",
         "-0.3903000742257974",
         "-0.742882457232163",
         "-0.8313799398295678",
         "-0.7793973537637188",
         "1.7918583004420232",
         "0.7257041521241208",
         "0.11642983366533553",
         "-0.2645289353235083",
         "-0.586730110278986",
         "-0.5528430225982113",
         "-0.3227285671094573",
         "-1.1115705293960008",
         "0.13251858403287997",
         "-0.041062929382180674",
         "0.31137714415315165",
         "-0.057274823089201676",
         "-0.3033673235451857",
         "-0.42077634879959636",
         "0.017770225908867412",
         "-0.3812480961798376",
         "0.732698621801497",
         "-0.47090462289360924",
         "-0.11726670982031218",
         "-0.6159685239994867",
         "-0.2670311720617242",
         "-0.5659145249041273",
         "-0.4352138372523926",
         "0.016237984295864868",
         "0.006114094578742896",
         "0.04567062503088491",
         "0.006687692423008061",
         "-0.10346759131257151",
         "-0.00598555135778619",
         "-0.03831406180942133",
         "-0.2741049145447891",
         "0.31791269476215067",
         "-0.4097836362608135",
         "0.7463147608503388",
         "0.04527398052757109",
         "0.0211375833180645",
         "0.018025139638194063",
         "-0.240992089172499",
         "-0.08468582415279666",
         "0.024125253526936744",
         "0.05589594294146432",
         "-0.2114016652113825",
         "-0.0840920928507351",
         "0.005422585764335328"
        ],
        [
         "1244077",
         "75.661198700868",
         "-107.03081985360187",
         "-0.009500314112711905",
         "0.4413247620149206",
         "-1.017752725597211",
         "-0.370727984252768",
         "-1.003886823035055",
         "0.15182392358398833",
         "0.18209409405778465",
         "-0.043044877821028164",
         "-0.2561285229449118",
         "-0.5825795332281812",
         "-1.772589049945614",
         "-0.4224890985860985",
         "0.799240443433262",
         "0.04737817416806439",
         "-0.21390310315938826",
         "-0.05844192471298004",
         "-0.3683732922383316",
         "-0.3895588739081094",
         "-0.006109053632707511",
         "-0.3690119596719",
         "0.7252899518933683",
         "-0.4520534721571868",
         "-0.10970395257582144",
         "-0.510941397807037",
         "-0.23170751818482097",
         "-0.5514442798554382",
         "-0.37544928215539364",
         "0.0051418999078438185",
         "-0.04690867333398546",
         "0.0005232266716971969",
         "0.002614449826895898",
         "-0.11245707225513804",
         "-0.015319098121402102",
         "-0.07147914035768548",
         "-0.35017615087056697",
         "0.30458524892108063",
         "-0.3395619895315196",
         "0.8047595333417585",
         "0.02454086617767448",
         "0.0164390170924999",
         "0.06810671044801805",
         "-0.2782097610284171",
         "-0.01689679305791264",
         "0.024209483070751853",
         "0.05622146893278424",
         "-0.23062427444589453",
         "-0.06365324564914518",
         "0.013497970388335005"
        ],
        [
         "5103626",
         "300.1161638657152",
         "-99.23511795476422",
         "-0.5626382724025234",
         "-0.04983871248992966",
         "-0.9229242469510772",
         "-0.6823923499135888",
         "1.9809981578938742",
         "0.4083291352766494",
         "-0.19470902900427683",
         "0.06321209503813893",
         "-0.4349112791179195",
         "0.2611857718824237",
         "0.20279156919155822",
         "-0.6011624412327194",
         "0.08739707610334885",
         "-0.4078224051691006",
         "0.053635356145919244",
         "-0.03896972241831054",
         "-0.3074794212227885",
         "-0.40844800659737773",
         "0.0040020311043253536",
         "-0.37339179261474315",
         "0.7297005665405722",
         "-0.46773110165259596",
         "-0.11469536287025298",
         "-0.5745293866537664",
         "-0.24789755902839225",
         "-0.5580842788893466",
         "-0.435204792534405",
         "0.02580923693523617",
         "0.017348108534067985",
         "0.03509080403325143",
         "-0.015904535770459787",
         "-0.09220350524279917",
         "0.0006676346331355183",
         "-0.030147703313116295",
         "-0.32372238319770935",
         "0.32034871524047026",
         "-0.4343178680241736",
         "0.7184887650340714",
         "0.058511246463968214",
         "0.015546464014652043",
         "0.04670514910257936",
         "-0.28066251289220623",
         "-0.07615360593223211",
         "0.007082989438555131",
         "0.055273166918362406",
         "-0.2124051751496759",
         "-0.10673555633176894",
         "0.0025281111127025864"
        ],
        [
         "6944323",
         "-854.8356649072391",
         "-22.33859200093598",
         "-1.0725362369867968",
         "-0.38650537991760114",
         "1.8746413995098825",
         "-0.7788726917908102",
         "-1.8376238953807644",
         "0.5042659068649491",
         "-0.09185728810992921",
         "-0.07758864138314468",
         "0.443844432892012",
         "-0.05349038912182914",
         "-1.4012414861125042",
         "-1.1379621141642373",
         "1.3245836548590848",
         "0.06350740969189739",
         "-1.3348217177936186",
         "-0.14252672922001752",
         "-0.44205416140726655",
         "-0.22570146751514225",
         "0.908500193621198",
         "0.24596005253710357",
         "-0.15652192744725865",
         "-0.3916584505443392",
         "-0.12744715198516157",
         "-0.8075421378331443",
         "-0.32215978934842615",
         "-0.6539028714003713",
         "0.11052065984941983",
         "0.024663601374665556",
         "-0.005427388629896867",
         "0.02097638939916842",
         "-0.02718159053004555",
         "-0.09689455559543142",
         "-0.027071680860291582",
         "-0.07420522046747885",
         "-0.42786302164269724",
         "0.28092622901927755",
         "-0.4192857486453575",
         "0.7731321031848833",
         "0.1089403591255832",
         "-0.0023973636173048153",
         "0.009484085396984053",
         "-0.25218653270957275",
         "0.11921812642022696",
         "0.003942697742087192",
         "0.022749042821773917",
         "-0.11733895877691566",
         "-0.01368168294775539",
         "-0.05839523009004973"
        ],
        [
         "5506191",
         "-228.33717845154843",
         "-22.45366955484443",
         "-2.365944970499174",
         "-0.3427005368662698",
         "1.7087970202237095",
         "-1.258619544202405",
         "0.7586246149207512",
         "1.047410314868949",
         "0.29366648767810405",
         "-0.4389200968508224",
         "0.02896899607219059",
         "-0.741339256698931",
         "-0.08417110609950629",
         "-0.02030356871432848",
         "-0.004390447914153606",
         "-1.8271154591601078",
         "0.9594488383492236",
         "-0.24152713197004322",
         "-0.5402597606027367",
         "-0.1544628941189115",
         "0.9044671284874897",
         "0.23440537496245345",
         "-0.14338925121610266",
         "-0.38643684118470967",
         "-0.12434106247409579",
         "-0.7841105136217523",
         "-0.2934728299952376",
         "-0.7312450455930158",
         "-0.21266928798161908",
         "0.021464022755428795",
         "-0.034773678824989",
         "0.03618280503059443",
         "-0.013220926773953418",
         "-0.10251223768359664",
         "-0.028040716031231032",
         "-0.0530524612182081",
         "-0.3325459948727093",
         "0.31935111596303145",
         "-0.35501624169656876",
         "0.7999574989911821",
         "0.0012230972379474458",
         "0.03286865241528443",
         "-0.01766591031761333",
         "-0.21183202346718719",
         "0.025375404331367937",
         "-0.035508033308161276",
         "0.18588373151421328",
         "-0.20960216546003332",
         "-0.03507624516025014",
         "0.06431827536537388"
        ],
        [
         "8579841",
         "-854.8345573167355",
         "-22.338855378498987",
         "-1.0705101212852624",
         "-0.5728036311573085",
         "0.7275304258610944",
         "-1.5106805417848248",
         "-1.7206025164396177",
         "1.3733728396475802",
         "0.2703082736931488",
         "-0.14126366029285348",
         "-0.100361575728843",
         "-0.6673991884578776",
         "-1.8186976305310416",
         "0.23402794837959254",
         "0.8935720217759755",
         "-0.8897817628563166",
         "-1.4953338143467083",
         "-0.3227029002279053",
         "-0.21693875012351616",
         "-0.30669143074755434",
         "0.017340040577279003",
         "-0.054888194396721435",
         "-0.05362123707550042",
         "0.47181880375063345",
         "-0.728131615363641",
         "-0.6300769242036758",
         "-0.30882164124387684",
         "-0.8766120839459457",
         "-0.48548284930638863",
         "0.0019445283415782484",
         "-0.06761677166895431",
         "-0.020065230915683678",
         "-0.06116740450927885",
         "-0.06297044607613529",
         "0.03837859160126778",
         "-0.15209098614780536",
         "-0.351713062349434",
         "0.35413189447219",
         "-0.5129153528679605",
         "0.668774995454553",
         "0.037088835424343186",
         "-0.00018223933638931208",
         "-0.046701764965810896",
         "-0.19407841106093499",
         "0.054575758123972154",
         "0.05165032425712915",
         "0.07193369052343979",
         "-0.11242276925893993",
         "-0.009997479053203093",
         "-0.021424779603923506"
        ],
        [
         "1847340",
         "-20.520212809394707",
         "-52.65787130355253",
         "-2.4482623481172934",
         "-0.45137868803745873",
         "1.4667357121100408",
         "1.4722346833966975",
         "0.6815106330790881",
         "-0.5293489815511452",
         "0.622367849763854",
         "-0.5761055530975961",
         "0.4802103872254782",
         "-0.8512915109948664",
         "1.6781520602727433",
         "0.12305890412463716",
         "-0.7886575575863939",
         "-2.13696889935641",
         "0.22973801232819335",
         "-0.26476456926408914",
         "-0.5360689103233567",
         "-0.2962469431331726",
         "0.0585085748995119",
         "-0.06279577246319876",
         "-0.029214775558854763",
         "0.4879519823610946",
         "-0.711558980301676",
         "-0.7480914214490662",
         "-0.37416152931303676",
         "-0.7366593472839411",
         "-0.19877220549210725",
         "0.006354244862855994",
         "-0.02940008947424648",
         "0.05809306394791562",
         "-0.07369315037517866",
         "-0.08085481972122734",
         "0.0052780232097880365",
         "-0.05137760745887307",
         "-0.3883263113918077",
         "0.38215862590219063",
         "-0.3513975039671873",
         "0.7798009489657264",
         "0.009124693648748461",
         "0.023243087564448324",
         "-0.03293550584287655",
         "-0.1697517804128453",
         "0.06313025824018985",
         "-0.03350568037380216",
         "0.18424772276547965",
         "-0.16836147420726705",
         "-0.04089420756966189",
         "0.020718194733974106"
        ],
        [
         "1226379",
         "-854.8341631906759",
         "-22.350766141537445",
         "-2.073960978002453",
         "0.6470935337486574",
         "-0.24898704031897367",
         "0.8476896066628056",
         "1.218117836080708",
         "0.4216233505331974",
         "0.6226430754806282",
         "-0.3266952015761127",
         "-0.03382731106834407",
         "-0.591912116580654",
         "1.8590622584373988",
         "0.07919298527915586",
         "-0.4411770084104182",
         "-0.7810515357154845",
         "0.371283724816156",
         "0.5430023870496768",
         "0.0210034479100226",
         "-0.09123539540532614",
         "-0.1530304547232012",
         "-0.5717682351004194",
         "-0.6376191439477626",
         "-0.44956547919107226",
         "-0.09209843087259187",
         "-0.32875873968632907",
         "-0.19900027522399907",
         "-0.34509129141626615",
         "-0.3348042262529172",
         "-0.0333652298630795",
         "-0.016713772042399717",
         "0.04141469263270112",
         "-0.033670581801080415",
         "-0.036698657551492",
         "0.05294421043257535",
         "0.004844546383706821",
         "-0.08936141167805603",
         "0.3552930272410319",
         "-0.38637087813159904",
         "0.6936661361954406",
         "-0.15499428424140518",
         "0.07023015346759467",
         "0.09184216347065122",
         "-0.2580613739987765",
         "-0.12786254074515663",
         "0.016426524088541276",
         "0.12884156387982187",
         "-0.12447994344638078",
         "-0.03284515460094156",
         "0.011401234925205752"
        ],
        [
         "5224377",
         "-854.8330574787802",
         "-22.338975621756315",
         "-1.079676228826",
         "-0.2883991092962207",
         "1.4783162656003026",
         "1.4625423949001568",
         "-2.276108653085263",
         "1.7612055839168588",
         "0.9232596958264087",
         "-0.0876030911498941",
         "0.3291537587336911",
         "-0.3444089552015068",
         "0.342315916089678",
         "-0.7778500640897401",
         "2.0619375931253163",
         "0.8547405717239902",
         "-1.2198670864380456",
         "0.06674268449054653",
         "-0.29456957120656146",
         "-0.5725223313276269",
         "-0.37587743141871194",
         "0.6718867547765559",
         "-0.14890846931089427",
         "-0.43750400483308877",
         "-0.13141160077313074",
         "-0.8758364632268977",
         "-0.3586851006851046",
         "-0.6736798942293959",
         "0.005718380012662103",
         "-0.01828021503878707",
         "0.0156848162374272",
         "0.0378456675095757",
         "-0.011424540219128912",
         "-0.08457243223220506",
         "0.015283189915918418",
         "-0.04356864013336324",
         "-0.3475755366419602",
         "0.336150494104549",
         "-0.3381447368768917",
         "0.808777937304642",
         "0.08939347693786814",
         "0.03282326932332898",
         "-0.0249677574478792",
         "-0.17968107079070933",
         "0.09981973003756305",
         "0.04029804704738599",
         "0.023674622967927016",
         "-0.0826194594335668",
         "-0.022039640066906355",
         "-0.06646072004895928"
        ],
        [
         "7729208",
         "639.7299862650682",
         "-189.0350988973534",
         "-2.237855440132285",
         "-1.9465235391074502",
         "1.8963189563404361",
         "-0.7568352708528994",
         "0.6704000400397545",
         "1.4056334297595474",
         "-0.11013684755961994",
         "-0.05122937508233625",
         "0.07381126148047387",
         "0.2643710915378905",
         "0.7617551485067423",
         "0.998602821150974",
         "-0.1611405095989521",
         "-1.0159393515116497",
         "1.4818699496032819",
         "0.09770180850685091",
         "-0.47383919206797326",
         "-0.5133260094864892",
         "-0.3936012555131586",
         "0.6593879751033648",
         "-0.14330283786485215",
         "-0.396205202695013",
         "-0.12349243186339484",
         "-0.8143425289709408",
         "-0.2817862742564119",
         "-0.7590009428965742",
         "-0.4125210584457708",
         "-0.011771039806477784",
         "-0.0005291527120058793",
         "0.044962035263624966",
         "-0.012858824648106327",
         "-0.09534374742694607",
         "0.02848733757466214",
         "-0.03050726927688785",
         "-0.29960139524046553",
         "0.36134880470479697",
         "-0.290670072563071",
         "0.8250220158094104",
         "-0.04680176802261776",
         "0.06477281580947744",
         "-0.06033585144922521",
         "-0.1415046784105041",
         "0.017555139688656837",
         "-0.02692348475039904",
         "0.18884686847512144",
         "-0.14637424661391574",
         "-0.07509624659729179",
         "0.03316409512413057"
        ],
        [
         "11647043",
         "-854.8351981259929",
         "-22.339043221494038",
         "-1.0693732190931118",
         "-1.6297706092031818",
         "0.5164298514604744",
         "0.836099686274382",
         "-1.841609068252895",
         "1.5669063498294158",
         "0.6166597267008316",
         "-0.0194028545704179",
         "-0.05510778212334766",
         "-0.4630160453416964",
         "-0.7876261999231347",
         "-1.5921145446421785",
         "1.432903158727014",
         "0.09149577681560252",
         "-1.249362890123887",
         "-0.21386192147112232",
         "-0.229879599772759",
         "-0.40915835251835575",
         "0.09739463945584287",
         "-0.05615680994295767",
         "-0.05164546799054432",
         "-0.05772176949739015",
         "-0.06158532337475947",
         "-0.9161212283111019",
         "0.7225502768375774",
         "-0.6488250168436919",
         "-0.37222177526597516",
         "0.0057455278448707075",
         "0.017296935983693154",
         "0.0008323144313588287",
         "0.00796936276092629",
         "-0.07246020229756944",
         "-0.004689778028741822",
         "-0.07970161521670874",
         "-0.31256858995401726",
         "0.340554594955344",
         "-0.38649789549420266",
         "0.7912475353391075",
         "0.02996219449350948",
         "0.02971514638877785",
         "-0.053132275111777746",
         "-0.13220489858781137",
         "0.0666438616287869",
         "0.055604404554427625",
         "0.036947397944716374",
         "-0.11893297247957221",
         "0.0062135848038968305",
         "-0.047380607373380394"
        ],
        [
         "11298857",
         "25.985309105549277",
         "406.39455128916774",
         "-7.827997142711708",
         "-1.8043369873410393",
         "-0.09721886057253248",
         "-0.014864019415531164",
         "-0.39873026698213915",
         "0.9038470561258216",
         "-0.08154825811037919",
         "0.1399992932736592",
         "-0.14095867711999024",
         "0.15418778824124685",
         "-0.24291911067297367",
         "-1.0906703325465896",
         "1.6719245441234674",
         "-0.009869646104349372",
         "-0.9773116994335378",
         "-0.03338511207220007",
         "-0.13304226182293144",
         "-0.3831143615415854",
         "0.09343277832783153",
         "-0.05337760508952641",
         "-0.048204714396115386",
         "-0.04541842799629425",
         "-0.05451013950265206",
         "-0.8866815504331454",
         "0.7457757696173604",
         "-0.628256279412221",
         "-0.44721394232561684",
         "0.012894420503564315",
         "0.0453174367820564",
         "0.014550769290348556",
         "-0.004335941200628284",
         "-0.07738304989393047",
         "0.002953715766073393",
         "-0.07492044509561455",
         "-0.32201580972599164",
         "0.30705217689835973",
         "-0.4315400198764944",
         "0.7611489412650064",
         "0.017897437002838412",
         "0.026732078251524828",
         "-0.029999454820621815",
         "-0.16617774868821514",
         "0.029052036302726986",
         "0.02768803557416713",
         "0.026131772073447107",
         "-0.11741994001443942",
         "-0.04257329392068976",
         "-0.052198697068136256"
        ],
        [
         "1601047",
         "-854.83296361916",
         "-22.338805904256418",
         "-1.0717705314910186",
         "-0.7874949349596513",
         "0.04297688594548432",
         "-2.1219971454718216",
         "-0.06470368415854054",
         "0.9435023183229003",
         "-0.10896600163747067",
         "-0.28249318102955207",
         "-0.13348851837302636",
         "-0.5899486962379213",
         "-0.042563437433378426",
         "0.7513498860277856",
         "1.4815167292975298",
         "0.0656725006932038",
         "-1.075072935790959",
         "-0.007619770081482319",
         "-0.11918294593517767",
         "-0.4445739505741388",
         "-0.012090240309822125",
         "-0.3601118096770421",
         "0.7085000702679551",
         "-0.5174265206258448",
         "-0.14219038415999266",
         "-0.6645130032366843",
         "-0.2590471363000056",
         "-0.7471833485958265",
         "-0.4365005658678451",
         "0.01548550402069723",
         "-0.010106991934060365",
         "-0.023209038316559637",
         "-0.044493404541604525",
         "-0.10844212999851652",
         "0.029614720192102123",
         "-0.07513818357823748",
         "-0.3131025610850802",
         "0.34452568919342874",
         "-0.5203146600603044",
         "0.6517645573894029",
         "0.037063038463717196",
         "0.005840899779605024",
         "-0.05132453779860442",
         "-0.1997173768739809",
         "-0.002705672766483494",
         "0.03753530838288077",
         "0.030333014838766534",
         "-0.06935537474859016",
         "-0.07398707671644199",
         "-0.06170427054799298"
        ],
        [
         "4615598",
         "741.4739683319212",
         "-163.40512949557512",
         "-2.739454154498443",
         "-2.049008963620438",
         "1.084671717335058",
         "-1.1619264352666243",
         "-0.19168704614914972",
         "1.931015968562742",
         "-0.03346966528394377",
         "0.08322822480573878",
         "-0.22484311576036167",
         "0.09782525404073075",
         "-0.45709939267381894",
         "0.49339836201078113",
         "0.5000256240392078",
         "-0.7895763199080389",
         "0.73476013738689",
         "0.0413939650225387",
         "-0.39555175226191086",
         "-0.4610480730527169",
         "0.00458850134322113",
         "-0.38581981362229156",
         "0.6982260397975594",
         "-0.45622023226227915",
         "-0.12976468046411502",
         "-0.6672134492539719",
         "-0.26243016429516436",
         "-0.6729822393951446",
         "-0.41102187083859787",
         "0.017332135981140254",
         "-0.027560418022564107",
         "0.01570185897184275",
         "0.01607505038333705",
         "-0.09220161501414718",
         "-0.004684748415895281",
         "-0.03982837038083446",
         "-0.31391399137293086",
         "0.3341620709054715",
         "-0.32413121980240245",
         "0.8290240432793922",
         "-0.010935319350864836",
         "0.05420140861117989",
         "-0.05218993165048723",
         "-0.1323018272954789",
         "0.017792795469880898",
         "-0.0023412556458883797",
         "0.14067302399101927",
         "-0.15614102509420086",
         "-0.03983413392341532",
         "0.013643903618844749"
        ],
        [
         "4473535",
         "-854.8308087861581",
         "-22.327456349480556",
         "-0.07638105204868806",
         "-0.3986191081624678",
         "0.8947611688573287",
         "-0.5205182981696065",
         "-0.002118348607409018",
         "2.318285289401799",
         "0.42881173482563706",
         "-0.01079576975236956",
         "-0.08113360126018429",
         "-0.13388861704772395",
         "1.3601295144902434",
         "0.4103800869403095",
         "-0.583728148925904",
         "-0.958655997792326",
         "0.8592757852996165",
         "0.584154061095262",
         "-0.0835268718961733",
         "0.03788989240958772",
         "0.8326935099684916",
         "0.23761506949841982",
         "-0.13134198732556338",
         "-0.3538831497106387",
         "-0.10414753617914152",
         "-0.4510572658579195",
         "-0.22259401613771296",
         "-0.3641520924022551",
         "-0.16768037730148458",
         "0.03371011584692918",
         "-0.007847156460523351",
         "0.04185785931218884",
         "-0.019132969192020885",
         "-0.036912462772748816",
         "0.013160769036765562",
         "0.02685404496350187",
         "-0.11489104800747307",
         "0.35702806611326",
         "-0.36466431124052495",
         "0.7623317746545547",
         "-0.16140606405297617",
         "0.08998862563688649",
         "0.046855867196300374",
         "-0.1840568998487318",
         "-0.09107073521262586",
         "0.009861482768987783",
         "0.16532137017850268",
         "-0.09589410490702002",
         "0.0065088158937170685",
         "0.010102898653143861"
        ],
        [
         "2890106",
         "304.2497730611219",
         "-84.69102487911685",
         "-1.74616812214891",
         "-0.8084865861322427",
         "0.9057806590415813",
         "0.5896330634794669",
         "-0.28836997407843923",
         "0.9495195687581086",
         "0.05954226895707011",
         "0.21550980803428568",
         "0.03819189769423375",
         "0.6281911230896562",
         "-0.18987720450472578",
         "-0.36435430508668554",
         "1.2042870354030355",
         "0.27912464697412365",
         "-0.6507552741513708",
         "-0.6390506509835367",
         "-0.1954896194050657",
         "0.017391248269341665",
         "0.856939758128801",
         "0.2502339049966079",
         "-0.1300955018902119",
         "-0.31399659965983534",
         "-0.07444246287469374",
         "-0.2500356958084161",
         "-0.1693353956621458",
         "-0.33947082396559025",
         "-0.2807957767564562",
         "0.0362346324215733",
         "-0.016579806098038392",
         "0.022960646903146326",
         "-0.02164217671114963",
         "-0.03699145663032707",
         "0.018996815142223906",
         "-0.016700793087916867",
         "-0.12441050341514706",
         "0.23764156770954006",
         "-0.39742841954423486",
         "0.804268502436916",
         "-0.10529939822305756",
         "-0.013028861275081481",
         "0.10216353320312946",
         "-0.2771463908073958",
         "4.632470831364421e-06",
         "-0.00687577210631906",
         "0.039713286747639666",
         "-0.0668449352824777",
         "-0.09970054320235967",
         "-0.01065892387770959"
        ],
        [
         "5018941",
         "758.4844641209347",
         "-206.28318313510928",
         "-1.282346123098138",
         "-1.9394992933152366",
         "1.4087481896257532",
         "0.26488263056477523",
         "-0.1801409513230473",
         "1.5317765477396268",
         "0.07867072539983087",
         "0.12930282032513304",
         "-0.005915274023788615",
         "0.4092187346515253",
         "0.3095227740026405",
         "0.6993573702661771",
         "-0.0042026155889423045",
         "-0.4078212773278379",
         "1.0652885228376658",
         "0.8233496868269601",
         "-0.0990615849885467",
         "0.032227212261608906",
         "0.8471107118362133",
         "0.23255751714910775",
         "-0.1333398287740186",
         "-0.30352442468196306",
         "-0.08657427196302114",
         "-0.41081169394470096",
         "-0.1882854062501588",
         "-0.3161169118806667",
         "-0.2674358277691834",
         "0.0343146758233794",
         "-0.01523531490293032",
         "0.056688830311690974",
         "-0.007926481712092818",
         "-0.04955046270178915",
         "0.010277210164024492",
         "0.029296570010613785",
         "-0.09376858967216428",
         "0.29313870897338334",
         "-0.28293525707274003",
         "0.8640094129578896",
         "-0.16694885613041865",
         "0.10489791753919862",
         "0.046406993139291336",
         "-0.16669110250597516",
         "-0.05128052141648004",
         "-0.004484214487083658",
         "0.15489008957205014",
         "-0.09884306302430115",
         "0.006213794538087545",
         "-0.0008085434853967836"
        ],
        [
         "11472854",
         "-854.8317320875703",
         "-22.31568028337558",
         "0.9304973424405594",
         "-0.9411796093054786",
         "1.222438988644606",
         "-0.564678028601763",
         "-1.0268450743245645",
         "-0.47486957226644916",
         "-0.6579378745612438",
         "0.19896912224858584",
         "0.47776672620291566",
         "0.6966764231290574",
         "-0.87811813129913",
         "0.05378763864620573",
         "0.49831095793857294",
         "-0.7154785083420264",
         "-0.8003495074803436",
         "-0.2000635258523861",
         "-0.41287152552337847",
         "-0.3482558626259175",
         "-0.10748001228888883",
         "-0.5703301114168212",
         "-0.6808788030497289",
         "-0.47841878986403913",
         "-0.12732236916921413",
         "-0.6653757683593606",
         "-0.26954036288227223",
         "-0.7327828102846935",
         "-0.21101996161674083",
         "-0.029308138303743462",
         "-0.027173088910050353",
         "0.0014289066277934645",
         "-0.041610098842538086",
         "-0.07588424665352062",
         "0.022150392173075094",
         "-0.08264692695883565",
         "-0.42813700794374554",
         "0.30546334785277957",
         "-0.39644918824034336",
         "0.7372590595955254",
         "0.032360564673399955",
         "0.008641926981804056",
         "0.005265804592610786",
         "-0.24088961951268495",
         "0.09935276492742721",
         "-0.016457665307489086",
         "0.07524432259378322",
         "-0.11735309386907941",
         "-0.048376607043640864",
         "-0.03045468643382309"
        ],
        [
         "1917086",
         "-149.16532511994524",
         "-33.937046282972794",
         "-0.3943006751198075",
         "-0.9394780030971274",
         "1.2347298167910175",
         "0.6509185068572467",
         "0.5215340226820608",
         "0.7907666630352577",
         "-0.534529053666826",
         "0.7009041983105649",
         "0.2169946643468262",
         "1.9232188123071374",
         "0.5919213691175425",
         "-0.2007030719181202",
         "0.01935911326945844",
         "-0.9429390296827219",
         "0.07190357882503577",
         "-0.1257947314318896",
         "-0.34917771016338356",
         "-0.3460289300255366",
         "-0.09762883207938063",
         "-0.5880331558585947",
         "-0.6773686718691412",
         "-0.4812250670704693",
         "-0.13048788446693302",
         "-0.6932878762290188",
         "-0.2771605188091619",
         "-0.7782548557664111",
         "-0.49039660132270546",
         "-0.002509761080614005",
         "0.013126231575610206",
         "0.053852875938828496",
         "-0.01638555843773229",
         "-0.024834029503939134",
         "0.02250008056083759",
         "-0.01127543834945291",
         "-0.3459880925573145",
         "0.30256096955788675",
         "-0.3573746465403881",
         "0.7700990845592445",
         "-0.004821024857450562",
         "0.048028356104416144",
         "0.008950578518034512",
         "-0.23430893853440726",
         "0.04140323801961554",
         "-0.017128614162500867",
         "0.11738972125612154",
         "-0.1534945709951514",
         "-0.08638110616245938",
         "0.017624707608920032"
        ],
        [
         "6395455",
         "191.24561864594511",
         "27.736180294278896",
         "-1.8104042073569904",
         "-0.08229102045553016",
         "0.7977648088658498",
         "0.16696853883770635",
         "-1.153090864359543",
         "0.008207211660647307",
         "0.4972019294206797",
         "-0.48329246644196",
         "0.1465514693512567",
         "-0.9372474653323513",
         "-0.8730236864401353",
         "1.1698728369382652",
         "0.45575819089545616",
         "0.29797433459500544",
         "-1.1973436551753773",
         "0.09232841101610154",
         "-0.22773346739464312",
         "-0.2741921646745591",
         "-0.13269264912421025",
         "-0.5633392396583586",
         "-0.6670512379066034",
         "-0.5050955008026689",
         "-0.13632468397175598",
         "-0.7323339269125829",
         "-0.23984337570913053",
         "-0.7678859389451761",
         "-0.47869431660774275",
         "-0.037527775538253295",
         "-0.04967331367855846",
         "-0.011854008698607872",
         "-0.06205558975236733",
         "-0.0891507427899662",
         "0.045708300951904014",
         "-0.08032889653691996",
         "-0.3060747849381285",
         "0.3663202406525131",
         "-0.43467581968011143",
         "0.6647958365030741",
         "0.0394894080689652",
         "0.0021399491962223677",
         "-0.03184588859569083",
         "-0.23017119674595457",
         "0.03651014202104766",
         "0.06165469204362402",
         "0.045679733455364385",
         "-0.0989775105430824",
         "-0.08788914432957824",
         "-0.03325607503182391"
        ],
        [
         "3501675",
         "777.1032692401109",
         "-168.5598743871525",
         "-0.7548786579007389",
         "-1.34720912098939",
         "1.655922329127062",
         "0.6226412598053377",
         "0.13377874859736727",
         "-0.45803851724560457",
         "-0.06160875150592113",
         "-0.07452779062982469",
         "0.3004205224830348",
         "0.22100620668996818",
         "-0.6937285645815103",
         "0.8778466528767483",
         "1.1124091697595841",
         "-1.5881526206413594",
         "0.49377705339937167",
         "-0.09098589062194197",
         "-0.5362388846178537",
         "-0.3313932335163858",
         "-0.08329281676883253",
         "-0.5791361063081032",
         "-0.6799574351620042",
         "-0.43481564135620093",
         "-0.10931891005912353",
         "-0.6653693016422205",
         "-0.2640127532536214",
         "-0.665696912130586",
         "-0.21310149757377425",
         "-0.04235115780488497",
         "-0.05998299147313631",
         "0.022979282296705834",
         "-0.01425134488458942",
         "-0.09920042278517589",
         "0.0023457055918972413",
         "-0.07641265313276382",
         "-0.38000982088648383",
         "0.2616252391921106",
         "-0.25837815897828875",
         "0.8713130100818712",
         "0.02435866466367298",
         "0.039394625152977585",
         "0.005806936063942135",
         "-0.21068402007520814",
         "0.10762385263910913",
         "-0.0643852946030052",
         "0.16172730561195117",
         "-0.19504752130690955",
         "-0.027597054869698656",
         "0.03729031363064941"
        ],
        [
         "5221932",
         "-854.8298181440246",
         "-22.315818396670426",
         "0.9310134752150514",
         "0.24292179652421575",
         "0.09522589379555124",
         "-1.9435534648552975",
         "-0.770714924691643",
         "0.26573510890872415",
         "-0.13954977883466269",
         "-0.1726825322454241",
         "-0.06715893135740625",
         "-0.48828483028032643",
         "-1.6365795404059902",
         "0.7103770902070233",
         "0.5631073317230485",
         "-0.5909386371025429",
         "-1.1252415020511048",
         "-0.21719630494646305",
         "-0.25112276406685097",
         "-0.455194415186574",
         "-0.4408262351084456",
         "0.6968192878826345",
         "-0.13635088825750669",
         "-0.42949903315028787",
         "-0.1226075418731788",
         "-0.6159147385359744",
         "-0.21316472163720188",
         "-0.7860790570370378",
         "-0.4754271070428052",
         "-0.023534701026760935",
         "-0.0390152388426101",
         "-0.05531629930405879",
         "-0.07082718105458179",
         "-0.1086054416861637",
         "0.061322910824967006",
         "-0.13096416785792747",
         "-0.35724368217620767",
         "0.36513884263124835",
         "-0.5056329184579402",
         "0.6382783069088498",
         "0.038019365438430736",
         "-0.011294972269083603",
         "-6.0635623504945446e-05",
         "-0.27229116611225634",
         "0.015591500096682753",
         "0.036391845797673295",
         "0.05626667212513815",
         "-0.1351922979665173",
         "-0.06675824529989938",
         "-0.011960607807086018"
        ],
        [
         "5060582",
         "-0.7230173685135242",
         "-55.511228526317005",
         "-0.4527093226670922",
         "0.3854929958663269",
         "0.5248033764444644",
         "-1.4288791780651546",
         "0.9855691698646307",
         "1.2719773981866747",
         "0.2548405652667858",
         "-0.30386191839858606",
         "-0.1876722522465609",
         "-0.5570872190052556",
         "0.44959312725093065",
         "-0.23462655129673737",
         "-0.5086814613245643",
         "-0.8117452826319872",
         "0.06662681593266108",
         "-0.09673075356765475",
         "-0.3769835228294264",
         "-0.47544191439162165",
         "-0.4153796469224714",
         "0.6759405909946083",
         "-0.12998120652174652",
         "-0.4234400135183578",
         "-0.12192012691857551",
         "-0.7331551240119349",
         "-0.2638946777044867",
         "-0.6996647928593036",
         "-0.33965484186375927",
         "-0.01613047258881441",
         "0.007559143385624198",
         "0.01475983297156688",
         "-0.039411063941612194",
         "-0.09343801764246781",
         "0.03857802814918815",
         "-0.06993112120577787",
         "-0.3322508791312308",
         "0.4065539478939683",
         "-0.4609702586455463",
         "0.653749319923958",
         "0.04316880556439007",
         "0.01008926030244485",
         "-0.006420149728575242",
         "-0.2449160409439838",
         "-0.047590570111147715",
         "0.023016417252576124",
         "0.09961769371646408",
         "-0.17379579893521707",
         "-0.088001021449727",
         "0.009926383385994959"
        ],
        [
         "4450216",
         "365.0672103454251",
         "-83.41395552878419",
         "-0.8857268482523137",
         "0.6229436844851644",
         "0.41794567900905527",
         "-1.5065256043511197",
         "-1.391442647495479",
         "0.3110705229637842",
         "0.04116664832066935",
         "-0.192705848760943",
         "0.05668507030137906",
         "-0.5424775527467163",
         "-1.50768005677557",
         "1.1382690918436669",
         "0.45924784916372247",
         "-0.1701318001348923",
         "-1.1792696940336438",
         "0.0037292774335712896",
         "-0.2627937280686712",
         "-0.4394799212512195",
         "-0.4501694802984497",
         "0.697086201165197",
         "-0.137413974435177",
         "-0.4184866665089369",
         "-0.1208709317256948",
         "-0.6394221554290073",
         "-0.19897446383624945",
         "-0.7604410290192323",
         "-0.4858978874854002",
         "-0.02249192981811213",
         "-0.03980317274833765",
         "-0.052270222626231946",
         "-0.07431896429883733",
         "-0.10815438988630535",
         "0.0614193305707178",
         "-0.11809085696750006",
         "-0.3595652917172485",
         "0.38619585565942544",
         "-0.48185899275106414",
         "0.6428524402160638",
         "0.037405716630310865",
         "-0.008701817660689368",
         "0.0027801906333315834",
         "-0.2741858512936983",
         "0.019073436363337262",
         "0.04997664347315536",
         "0.05064451010056673",
         "-0.12963901747319515",
         "-0.08773904216421755",
         "-0.021160103264295113"
        ],
        [
         "10221767",
         "762.4450346283529",
         "-206.84678623009873",
         "-0.281801332762492",
         "-1.5321041099409305",
         "1.087095343573977",
         "-1.4634042018349935",
         "0.4073678672645859",
         "1.0235799897462174",
         "0.034906328670325865",
         "-0.3118744932884357",
         "-0.1707474392293905",
         "-0.5599681321513899",
         "-0.5947165443094116",
         "0.9160915274528358",
         "0.34197335408256485",
         "-0.9095571033113335",
         "0.8940215070045479",
         "0.03862574240147863",
         "-0.43648549776286655",
         "-0.47928300549186775",
         "-0.40519871138316044",
         "0.669579712471938",
         "-0.13954905224190053",
         "-0.38246505075842413",
         "-0.11223681512144609",
         "-0.7060942385110842",
         "-0.24061184871775979",
         "-0.7060348641163212",
         "-0.40343576691999106",
         "-0.027593675380576277",
         "-0.032803436654859915",
         "0.011888596694140937",
         "-0.019585142115048332",
         "-0.12080268872812966",
         "0.030999001780903014",
         "-0.0867404738161645",
         "-0.3093045839046262",
         "0.3492504567708069",
         "-0.3406444013667449",
         "0.787786594744989",
         "-0.00557329638091586",
         "0.03893749975022092",
         "-0.03975485477636986",
         "-0.1729179327623593",
         "0.004684221070200695",
         "-0.010367472287283385",
         "0.1497355793600175",
         "-0.17023577678010862",
         "-0.05658924269718407",
         "0.025224522385572084"
        ],
        [
         "5460357",
         "-854.8309099924969",
         "-22.339265248869037",
         "-1.0768771832227546",
         "1.3713835586034508",
         "-0.3300650045419251",
         "-0.17405449052586103",
         "-1.4057562509885226",
         "-0.010806453269130267",
         "0.7877771450188465",
         "-0.6041566673912613",
         "0.11429230014812983",
         "-1.5957134130318307",
         "-0.22823128909263035",
         "1.8058514290950003",
         "1.068530536166771",
         "-0.08890190477942764",
         "-0.5097367276261549",
         "0.014210816595848656",
         "-0.27457127594515446",
         "-0.04669321701610782",
         "0.8568387861802773",
         "0.2617614232916693",
         "-0.12575684723360825",
         "-0.4258632142962068",
         "-0.12925108737516325",
         "-0.7156513661459135",
         "-0.24664483448518845",
         "-0.7426552656037401",
         "-0.40086300523662693",
         "0.014814329806880501",
         "-0.06246035640553373",
         "-0.004340237427926466",
         "-0.0717546287406661",
         "-0.1255680756192234",
         "-0.0042873590222638775",
         "-0.06132886033940363",
         "-0.312774434471699",
         "0.3389928156814791",
         "-0.3878517701240607",
         "0.7371826588052858",
         "-0.005634545526832874",
         "0.013668528379025463",
         "0.009616544705513229",
         "-0.2546117658062271",
         "0.009893126431617896",
         "0.033543677432456315",
         "0.09155252815154724",
         "-0.14301559228829477",
         "-0.08828981726554515",
         "0.00654338011987177"
        ],
        [
         "3286438",
         "940.3846595823582",
         "-192.3147360849119",
         "-2.8174703421287073",
         "-1.2264799710405248",
         "0.8714402845028462",
         "0.827658117119461",
         "-0.09264717582683443",
         "0.3982585737988826",
         "0.5727723915611244",
         "-0.36390928002159856",
         "-0.024268368992431892",
         "-0.7735531653569001",
         "-0.47635131861360946",
         "0.19257271009430899",
         "1.0588361486157258",
         "-0.7223794065101676",
         "0.6805842783016491",
         "0.013462722369247015",
         "-0.3917508209143156",
         "-0.09931004461901712",
         "0.9080201382532276",
         "0.23396614392329282",
         "-0.13200195992385072",
         "-0.3552738444845579",
         "-0.10364269055415798",
         "-0.654962708262366",
         "-0.23993741124205206",
         "-0.6843741711085364",
         "-0.47490900816027426",
         "0.02285403036486772",
         "-0.05066588972328659",
         "0.05538703327183761",
         "-0.010053078068315197",
         "-0.11160827110424112",
         "-0.0297419522901637",
         "-0.03657697077736656",
         "-0.26867636208204315",
         "0.26906542072367207",
         "-0.2721620109765813",
         "0.8959499479028195",
         "-0.024502462140641446",
         "0.053479150230630774",
         "-0.015388080714415886",
         "-0.17434052836801928",
         "0.03361026858917861",
         "-0.010433904984757773",
         "0.14846391120978814",
         "-0.20259870313407685",
         "-0.04013722834874939",
         "0.0411997250578633"
        ],
        [
         "10254671",
         "-854.8353334728436",
         "-22.350482906047205",
         "-2.0692163373621337",
         "0.6940521444405124",
         "-0.2484548102339389",
         "-2.517769031997823",
         "-1.446401445143825",
         "1.0275727668866936",
         "0.1190620275361137",
         "-0.2294680009152873",
         "-0.24632470335257578",
         "-0.9519002064014137",
         "-2.0684633661595457",
         "0.5013446029846942",
         "0.6926962273506857",
         "-0.28389800274847465",
         "-1.1806840931273992",
         "-0.19265333535161083",
         "-0.2386104903555769",
         "-0.2732441549373185",
         "0.006463614577179259",
         "-0.05330246082752126",
         "-0.042317668823642914",
         "0.4730297084126924",
         "-0.7261231232428536",
         "-0.6349723541961809",
         "-0.3024263821371835",
         "-0.8146671741155795",
         "-0.46341787059648765",
         "-0.005351509879560093",
         "-0.06402143696716733",
         "-0.01262771382737738",
         "-0.060525196975283586",
         "-0.07870827687946871",
         "0.03364164703831648",
         "-0.16057941414061833",
         "-0.3563003919337341",
         "0.35795862763431674",
         "-0.521382321614458",
         "0.6325492884981228",
         "0.036221844057619274",
         "-0.011113772742025116",
         "0.007721991890635216",
         "-0.2716365973640952",
         "-0.010322771309202658",
         "0.05799127778249134",
         "0.048333298113141014",
         "-0.14592637568297287",
         "-0.058440619847941744",
         "-0.014474417793062199"
        ],
        [
         "9738336",
         "-854.8324792762013",
         "-22.33929297622079",
         "-1.0736737156839558",
         "-0.2007570824048992",
         "-0.25783177271945273",
         "2.1284070017832626",
         "-0.40621901587394615",
         "0.22172171838675148",
         "0.8102389280704272",
         "-0.15100813366649105",
         "0.03782376749523773",
         "-0.47622235958020936",
         "0.3797320308058278",
         "-0.23599978215197548",
         "2.4667736710777675",
         "-0.1520611936229282",
         "-0.4085649234967164",
         "-0.09612920130590866",
         "-0.22820124987537455",
         "-0.3001745192092425",
         "-0.07345956654254575",
         "-0.5797432974807467",
         "-0.6613418900220229",
         "-0.48481904403943205",
         "-0.11415980048153249",
         "-0.6307262122505674",
         "-0.29139555729868616",
         "-0.6831087012652132",
         "-0.3584690016539806",
         "-0.03877411707489246",
         "-0.03941526392434296",
         "0.05559725990495673",
         "-0.003951214501163695",
         "-0.08350563772965829",
         "-0.0005065946433460439",
         "-0.0514337090845261",
         "-0.2906968243536256",
         "0.24982143046778066",
         "-0.2903825445402526",
         "0.8487616700846524",
         "0.019594229875913",
         "0.0461743456355443",
         "0.01981524496953515",
         "-0.21257614075076245",
         "0.04734101348965673",
         "-0.0004150320089469986",
         "0.07935188084404868",
         "-0.16900494878701602",
         "-0.03727405836263946",
         "0.0051776498935441305"
        ],
        [
         "3802902",
         "969.0835071375332",
         "-196.48582647277746",
         "-2.8287343489148293",
         "-2.2441165910233574",
         "0.5855413955536748",
         "0.5644007284256204",
         "-0.31620366989492216",
         "2.1143812247412033",
         "0.25049299908711986",
         "0.20400326852927822",
         "-0.2236053874394622",
         "0.29876370012789577",
         "0.7135006915232793",
         "0.3986913330004194",
         "-0.04957947433167498",
         "0.19353639686183693",
         "1.379841374598809",
         "0.2717876623894264",
         "-0.35464643697631826",
         "-0.28903836006766054",
         "-0.10093397520309227",
         "-0.6075971123241263",
         "-0.6706217603751694",
         "-0.45571690867216386",
         "-0.12569223011035552",
         "-0.711145286606898",
         "-0.2615169234144283",
         "-0.6935176340503737",
         "-0.5829170737791367",
         "-0.022413054106520367",
         "-0.017238727548946634",
         "0.09454643261611231",
         "0.02593373056477204",
         "-0.05747260440167345",
         "0.0013117294288779256",
         "0.0014489878889010393",
         "-0.251488674881046",
         "0.3428824672759304",
         "-0.232347556530696",
         "0.8531760767578115",
         "-0.06781300414870961",
         "0.08602870632495153",
         "-0.05157052852290106",
         "-0.10081641809272854",
         "-0.027863430984662124",
         "0.023279444716212086",
         "0.14649035507613753",
         "-0.14847482185884567",
         "-0.08227572800860507",
         "0.014346916654124745"
        ],
        [
         "4856159",
         "-854.8303897703621",
         "-22.3277376363781",
         "-0.07550856385146387",
         "0.42467868827042765",
         "0.22243132832587414",
         "1.125652324904489",
         "-0.4974134257307669",
         "1.1215547284952643",
         "1.1723774783555037",
         "-0.4928440532709754",
         "-0.03337428274810412",
         "-1.408002785264307",
         "0.7543451360683309",
         "-0.005977171933016223",
         "-0.2238326861817196",
         "-0.8414615974362728",
         "1.1690969698130937",
         "-0.15694648987356435",
         "-0.4112791576214567",
         "-0.4380635943940343",
         "-0.4249888619196659",
         "0.6852231722700074",
         "-0.10373390623149899",
         "-0.4352189285657941",
         "-0.13835597560174148",
         "-0.7315064372436582",
         "-0.2722533604788304",
         "-0.7637481886279086",
         "-0.5206752765125725",
         "-0.049026843569199355",
         "-0.08041473702175372",
         "-0.11136282961930816",
         "-0.35992440497709743",
         "0.23232414628227085",
         "-0.6547113946391239",
         "0.160884100399386",
         "-0.2596940763419627",
         "-0.26452650184826776",
         "0.37395362246122094",
         "0.1870223522998896",
         "-0.1097665188816196",
         "0.067683450820441",
         "-0.051383713797522046",
         "-0.1141481705779707",
         "0.0010213831513539579",
         "0.0160470385045845",
         "0.19572624102688577",
         "-0.18997737194981576",
         "-0.04506280559817129",
         "0.06524670053347426"
        ],
        [
         "4332944",
         "114.1301880260562",
         "11.650662474545804",
         "-2.4681138062455874",
         "1.5795119091373202",
         "1.3939151856110703",
         "-1.1858051328959789",
         "-1.2346753550549927",
         "0.03949602106242056",
         "0.1245551873935416",
         "-0.2675938351439411",
         "0.37175266643271904",
         "-0.44053691935503503",
         "-1.212084846366435",
         "0.51674126183729",
         "0.6389635953125563",
         "-0.4425576456465986",
         "-1.1632168814645807",
         "-0.048627168048354694",
         "-0.43495853271907564",
         "-0.5137620820046517",
         "-0.4483374145519452",
         "0.7153203777319258",
         "-0.13208451674407892",
         "-0.42504894314440356",
         "-0.1430012375272885",
         "-0.7910304043073344",
         "-0.2618454652821332",
         "-0.6900449223030423",
         "-0.07530472715544875",
         "-0.052807722101224815",
         "-0.06035598269310029",
         "-0.18916811951899767",
         "-0.41648088388908217",
         "0.2184743641327569",
         "-0.6280840739675191",
         "0.0785026526615504",
         "-0.43648612669970277",
         "-0.28440397711998366",
         "0.17555433141093185",
         "0.022647302744276378",
         "0.07297981902165257",
         "-0.010964967100074625",
         "0.0023549401609764126",
         "-0.2648986431967395",
         "0.0925780936265949",
         "0.007719245766823627",
         "0.05897304947874247",
         "-0.13014877275487052",
         "-0.0566475604192546",
         "-0.02965036423584755"
        ]
       ],
       "shape": {
        "columns": 50,
        "rows": 13184010
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca0</th>\n",
       "      <th>pca1</th>\n",
       "      <th>pca2</th>\n",
       "      <th>pca3</th>\n",
       "      <th>pca4</th>\n",
       "      <th>pca5</th>\n",
       "      <th>pca6</th>\n",
       "      <th>pca7</th>\n",
       "      <th>pca8</th>\n",
       "      <th>pca9</th>\n",
       "      <th>pca10</th>\n",
       "      <th>pca11</th>\n",
       "      <th>pca12</th>\n",
       "      <th>pca13</th>\n",
       "      <th>pca14</th>\n",
       "      <th>pca15</th>\n",
       "      <th>pca16</th>\n",
       "      <th>pca17</th>\n",
       "      <th>pca18</th>\n",
       "      <th>pca19</th>\n",
       "      <th>pca20</th>\n",
       "      <th>pca21</th>\n",
       "      <th>pca22</th>\n",
       "      <th>pca23</th>\n",
       "      <th>pca24</th>\n",
       "      <th>pca25</th>\n",
       "      <th>pca26</th>\n",
       "      <th>pca27</th>\n",
       "      <th>pca28</th>\n",
       "      <th>pca29</th>\n",
       "      <th>pca30</th>\n",
       "      <th>pca31</th>\n",
       "      <th>pca32</th>\n",
       "      <th>pca33</th>\n",
       "      <th>pca34</th>\n",
       "      <th>pca35</th>\n",
       "      <th>pca36</th>\n",
       "      <th>pca37</th>\n",
       "      <th>pca38</th>\n",
       "      <th>pca39</th>\n",
       "      <th>pca40</th>\n",
       "      <th>pca41</th>\n",
       "      <th>pca42</th>\n",
       "      <th>pca43</th>\n",
       "      <th>pca44</th>\n",
       "      <th>pca45</th>\n",
       "      <th>pca46</th>\n",
       "      <th>pca47</th>\n",
       "      <th>pca48</th>\n",
       "      <th>pca49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237129</th>\n",
       "      <td>-854.833838</td>\n",
       "      <td>-22.350535</td>\n",
       "      <td>-2.076370</td>\n",
       "      <td>0.440297</td>\n",
       "      <td>0.167337</td>\n",
       "      <td>-0.572813</td>\n",
       "      <td>-1.737709</td>\n",
       "      <td>1.939359</td>\n",
       "      <td>0.598997</td>\n",
       "      <td>-0.055869</td>\n",
       "      <td>-0.137670</td>\n",
       "      <td>-0.548254</td>\n",
       "      <td>-0.542312</td>\n",
       "      <td>0.298613</td>\n",
       "      <td>2.088348</td>\n",
       "      <td>0.848927</td>\n",
       "      <td>-0.670052</td>\n",
       "      <td>0.047257</td>\n",
       "      <td>0.212088</td>\n",
       "      <td>-0.128773</td>\n",
       "      <td>-0.051730</td>\n",
       "      <td>-0.342995</td>\n",
       "      <td>0.748262</td>\n",
       "      <td>-0.345468</td>\n",
       "      <td>-0.041718</td>\n",
       "      <td>0.132528</td>\n",
       "      <td>-0.142064</td>\n",
       "      <td>0.022071</td>\n",
       "      <td>-0.059568</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>-0.065895</td>\n",
       "      <td>-0.026877</td>\n",
       "      <td>0.021622</td>\n",
       "      <td>-0.050331</td>\n",
       "      <td>0.102271</td>\n",
       "      <td>-0.066844</td>\n",
       "      <td>0.130475</td>\n",
       "      <td>0.551934</td>\n",
       "      <td>0.570553</td>\n",
       "      <td>-0.210321</td>\n",
       "      <td>-0.257098</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0.173589</td>\n",
       "      <td>-0.273864</td>\n",
       "      <td>-0.091286</td>\n",
       "      <td>0.039982</td>\n",
       "      <td>-0.003104</td>\n",
       "      <td>-0.021177</td>\n",
       "      <td>-0.032929</td>\n",
       "      <td>0.007210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084368</th>\n",
       "      <td>-854.834141</td>\n",
       "      <td>-22.338888</td>\n",
       "      <td>-1.070168</td>\n",
       "      <td>-0.928008</td>\n",
       "      <td>0.109072</td>\n",
       "      <td>0.652765</td>\n",
       "      <td>1.616179</td>\n",
       "      <td>-0.338744</td>\n",
       "      <td>0.239957</td>\n",
       "      <td>-0.415272</td>\n",
       "      <td>-0.021180</td>\n",
       "      <td>-0.514327</td>\n",
       "      <td>1.026836</td>\n",
       "      <td>-0.051468</td>\n",
       "      <td>0.161360</td>\n",
       "      <td>-0.747007</td>\n",
       "      <td>0.014852</td>\n",
       "      <td>-0.861847</td>\n",
       "      <td>-0.250895</td>\n",
       "      <td>-0.119135</td>\n",
       "      <td>-0.133813</td>\n",
       "      <td>-0.564526</td>\n",
       "      <td>-0.642091</td>\n",
       "      <td>-0.424731</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>-0.197131</td>\n",
       "      <td>-0.176772</td>\n",
       "      <td>-0.352992</td>\n",
       "      <td>-0.315177</td>\n",
       "      <td>-0.040223</td>\n",
       "      <td>-0.038654</td>\n",
       "      <td>0.016543</td>\n",
       "      <td>-0.037551</td>\n",
       "      <td>-0.054355</td>\n",
       "      <td>0.055144</td>\n",
       "      <td>-0.039692</td>\n",
       "      <td>-0.116110</td>\n",
       "      <td>0.300608</td>\n",
       "      <td>-0.405332</td>\n",
       "      <td>0.724086</td>\n",
       "      <td>-0.120801</td>\n",
       "      <td>-0.010670</td>\n",
       "      <td>0.046517</td>\n",
       "      <td>-0.184143</td>\n",
       "      <td>-0.035533</td>\n",
       "      <td>-0.030640</td>\n",
       "      <td>0.081651</td>\n",
       "      <td>-0.096209</td>\n",
       "      <td>-0.106677</td>\n",
       "      <td>0.052260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029548</th>\n",
       "      <td>147.713096</td>\n",
       "      <td>-77.108846</td>\n",
       "      <td>-2.508873</td>\n",
       "      <td>0.219041</td>\n",
       "      <td>0.183271</td>\n",
       "      <td>-0.052362</td>\n",
       "      <td>-1.468815</td>\n",
       "      <td>0.891923</td>\n",
       "      <td>0.671056</td>\n",
       "      <td>-0.296954</td>\n",
       "      <td>-0.029719</td>\n",
       "      <td>-1.096354</td>\n",
       "      <td>-0.770653</td>\n",
       "      <td>-0.639487</td>\n",
       "      <td>0.545767</td>\n",
       "      <td>-0.418540</td>\n",
       "      <td>-0.463175</td>\n",
       "      <td>0.530344</td>\n",
       "      <td>0.035675</td>\n",
       "      <td>-0.098316</td>\n",
       "      <td>-0.162530</td>\n",
       "      <td>-0.570328</td>\n",
       "      <td>-0.655989</td>\n",
       "      <td>-0.407679</td>\n",
       "      <td>-0.078887</td>\n",
       "      <td>-0.174331</td>\n",
       "      <td>-0.140635</td>\n",
       "      <td>-0.348590</td>\n",
       "      <td>-0.346866</td>\n",
       "      <td>-0.048655</td>\n",
       "      <td>-0.071341</td>\n",
       "      <td>-0.003489</td>\n",
       "      <td>-0.006502</td>\n",
       "      <td>-0.044877</td>\n",
       "      <td>0.046853</td>\n",
       "      <td>-0.069222</td>\n",
       "      <td>-0.125848</td>\n",
       "      <td>0.334864</td>\n",
       "      <td>-0.390163</td>\n",
       "      <td>0.723194</td>\n",
       "      <td>-0.134809</td>\n",
       "      <td>0.043661</td>\n",
       "      <td>0.057495</td>\n",
       "      <td>-0.173647</td>\n",
       "      <td>-0.040443</td>\n",
       "      <td>0.051205</td>\n",
       "      <td>0.059454</td>\n",
       "      <td>-0.133284</td>\n",
       "      <td>0.035110</td>\n",
       "      <td>0.017812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11163145</th>\n",
       "      <td>-854.831051</td>\n",
       "      <td>-22.315751</td>\n",
       "      <td>0.932171</td>\n",
       "      <td>-1.247213</td>\n",
       "      <td>0.264628</td>\n",
       "      <td>0.378429</td>\n",
       "      <td>1.092836</td>\n",
       "      <td>-0.747042</td>\n",
       "      <td>-0.019225</td>\n",
       "      <td>-0.376363</td>\n",
       "      <td>-0.005954</td>\n",
       "      <td>-0.375436</td>\n",
       "      <td>-0.156368</td>\n",
       "      <td>0.354747</td>\n",
       "      <td>-0.050449</td>\n",
       "      <td>-0.307445</td>\n",
       "      <td>-0.060767</td>\n",
       "      <td>-0.807887</td>\n",
       "      <td>-0.260028</td>\n",
       "      <td>-0.295990</td>\n",
       "      <td>-0.442526</td>\n",
       "      <td>0.695511</td>\n",
       "      <td>-0.105206</td>\n",
       "      <td>-0.350451</td>\n",
       "      <td>-0.069121</td>\n",
       "      <td>-0.235673</td>\n",
       "      <td>-0.162171</td>\n",
       "      <td>-0.369080</td>\n",
       "      <td>-0.373825</td>\n",
       "      <td>-0.024298</td>\n",
       "      <td>-0.026886</td>\n",
       "      <td>-0.015455</td>\n",
       "      <td>-0.058525</td>\n",
       "      <td>-0.081886</td>\n",
       "      <td>0.080335</td>\n",
       "      <td>-0.052614</td>\n",
       "      <td>-0.108992</td>\n",
       "      <td>0.310271</td>\n",
       "      <td>-0.403620</td>\n",
       "      <td>0.745579</td>\n",
       "      <td>-0.123430</td>\n",
       "      <td>-0.017223</td>\n",
       "      <td>0.049851</td>\n",
       "      <td>-0.204998</td>\n",
       "      <td>-0.022656</td>\n",
       "      <td>-0.019727</td>\n",
       "      <td>0.065002</td>\n",
       "      <td>-0.089580</td>\n",
       "      <td>-0.117794</td>\n",
       "      <td>0.048885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12079249</th>\n",
       "      <td>-119.476685</td>\n",
       "      <td>-38.252221</td>\n",
       "      <td>-0.403234</td>\n",
       "      <td>-0.088713</td>\n",
       "      <td>0.273856</td>\n",
       "      <td>0.885572</td>\n",
       "      <td>-0.906457</td>\n",
       "      <td>-0.789604</td>\n",
       "      <td>0.586895</td>\n",
       "      <td>-0.564328</td>\n",
       "      <td>0.173975</td>\n",
       "      <td>-1.293512</td>\n",
       "      <td>-1.045807</td>\n",
       "      <td>-0.493408</td>\n",
       "      <td>0.800315</td>\n",
       "      <td>-0.377958</td>\n",
       "      <td>-0.731310</td>\n",
       "      <td>0.488236</td>\n",
       "      <td>0.055338</td>\n",
       "      <td>-0.272298</td>\n",
       "      <td>-0.448355</td>\n",
       "      <td>0.696611</td>\n",
       "      <td>-0.107243</td>\n",
       "      <td>-0.339225</td>\n",
       "      <td>-0.062423</td>\n",
       "      <td>-0.195257</td>\n",
       "      <td>-0.137837</td>\n",
       "      <td>-0.358293</td>\n",
       "      <td>-0.378293</td>\n",
       "      <td>-0.034077</td>\n",
       "      <td>-0.053095</td>\n",
       "      <td>-0.025850</td>\n",
       "      <td>-0.046371</td>\n",
       "      <td>-0.087511</td>\n",
       "      <td>0.072096</td>\n",
       "      <td>-0.073661</td>\n",
       "      <td>-0.109357</td>\n",
       "      <td>0.314965</td>\n",
       "      <td>-0.391231</td>\n",
       "      <td>0.759849</td>\n",
       "      <td>-0.127114</td>\n",
       "      <td>0.031212</td>\n",
       "      <td>0.063480</td>\n",
       "      <td>-0.202389</td>\n",
       "      <td>-0.007835</td>\n",
       "      <td>0.036338</td>\n",
       "      <td>0.045206</td>\n",
       "      <td>-0.129339</td>\n",
       "      <td>0.028349</td>\n",
       "      <td>0.012828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4840623</th>\n",
       "      <td>1446.920810</td>\n",
       "      <td>1804.960411</td>\n",
       "      <td>16.114719</td>\n",
       "      <td>-2.422619</td>\n",
       "      <td>1.610649</td>\n",
       "      <td>0.672875</td>\n",
       "      <td>0.969259</td>\n",
       "      <td>-0.592852</td>\n",
       "      <td>0.183473</td>\n",
       "      <td>-0.746838</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>-1.218365</td>\n",
       "      <td>0.083777</td>\n",
       "      <td>0.472713</td>\n",
       "      <td>0.095803</td>\n",
       "      <td>-1.852203</td>\n",
       "      <td>1.153305</td>\n",
       "      <td>0.728748</td>\n",
       "      <td>0.041038</td>\n",
       "      <td>-0.053026</td>\n",
       "      <td>0.011305</td>\n",
       "      <td>-0.055739</td>\n",
       "      <td>0.029012</td>\n",
       "      <td>0.410431</td>\n",
       "      <td>0.748450</td>\n",
       "      <td>-0.466618</td>\n",
       "      <td>-0.281612</td>\n",
       "      <td>-0.387750</td>\n",
       "      <td>-0.185651</td>\n",
       "      <td>0.043890</td>\n",
       "      <td>-0.232125</td>\n",
       "      <td>0.200536</td>\n",
       "      <td>0.158804</td>\n",
       "      <td>-0.229552</td>\n",
       "      <td>-0.207657</td>\n",
       "      <td>-0.536611</td>\n",
       "      <td>-0.010809</td>\n",
       "      <td>-0.290260</td>\n",
       "      <td>-0.307992</td>\n",
       "      <td>-0.237195</td>\n",
       "      <td>-0.266611</td>\n",
       "      <td>0.054686</td>\n",
       "      <td>0.025843</td>\n",
       "      <td>-0.122352</td>\n",
       "      <td>-0.085951</td>\n",
       "      <td>-0.067543</td>\n",
       "      <td>0.059791</td>\n",
       "      <td>-0.030700</td>\n",
       "      <td>0.073462</td>\n",
       "      <td>-0.044373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3552614</th>\n",
       "      <td>1481.735235</td>\n",
       "      <td>1815.057061</td>\n",
       "      <td>15.927770</td>\n",
       "      <td>-1.738535</td>\n",
       "      <td>1.102894</td>\n",
       "      <td>0.766987</td>\n",
       "      <td>-1.048087</td>\n",
       "      <td>0.406609</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.025129</td>\n",
       "      <td>-0.039639</td>\n",
       "      <td>0.033922</td>\n",
       "      <td>-1.720980</td>\n",
       "      <td>-0.440556</td>\n",
       "      <td>1.980514</td>\n",
       "      <td>-0.355618</td>\n",
       "      <td>-1.014802</td>\n",
       "      <td>0.132178</td>\n",
       "      <td>-0.074262</td>\n",
       "      <td>-0.259097</td>\n",
       "      <td>0.046958</td>\n",
       "      <td>-0.056985</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>0.344622</td>\n",
       "      <td>0.708491</td>\n",
       "      <td>-0.775352</td>\n",
       "      <td>-0.352902</td>\n",
       "      <td>-0.731150</td>\n",
       "      <td>-0.293085</td>\n",
       "      <td>0.061118</td>\n",
       "      <td>-0.207876</td>\n",
       "      <td>0.194648</td>\n",
       "      <td>0.166185</td>\n",
       "      <td>-0.225491</td>\n",
       "      <td>-0.233954</td>\n",
       "      <td>-0.589453</td>\n",
       "      <td>-0.242532</td>\n",
       "      <td>-0.328401</td>\n",
       "      <td>-0.386488</td>\n",
       "      <td>-0.269394</td>\n",
       "      <td>-0.055422</td>\n",
       "      <td>0.010671</td>\n",
       "      <td>0.013124</td>\n",
       "      <td>-0.213789</td>\n",
       "      <td>0.007008</td>\n",
       "      <td>-0.020031</td>\n",
       "      <td>-0.065807</td>\n",
       "      <td>-0.036923</td>\n",
       "      <td>0.014594</td>\n",
       "      <td>-0.126170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919427</th>\n",
       "      <td>1548.791783</td>\n",
       "      <td>1824.509533</td>\n",
       "      <td>15.677436</td>\n",
       "      <td>-1.876378</td>\n",
       "      <td>1.746183</td>\n",
       "      <td>0.700656</td>\n",
       "      <td>-1.643239</td>\n",
       "      <td>0.711923</td>\n",
       "      <td>0.211755</td>\n",
       "      <td>-0.202342</td>\n",
       "      <td>0.123060</td>\n",
       "      <td>-0.448522</td>\n",
       "      <td>-1.297856</td>\n",
       "      <td>-0.692133</td>\n",
       "      <td>1.638966</td>\n",
       "      <td>-0.015737</td>\n",
       "      <td>-1.040638</td>\n",
       "      <td>0.249941</td>\n",
       "      <td>0.238326</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>-0.026771</td>\n",
       "      <td>-0.041061</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.485591</td>\n",
       "      <td>0.788253</td>\n",
       "      <td>-0.008662</td>\n",
       "      <td>-0.209193</td>\n",
       "      <td>0.100622</td>\n",
       "      <td>0.095191</td>\n",
       "      <td>0.042284</td>\n",
       "      <td>-0.231527</td>\n",
       "      <td>0.149686</td>\n",
       "      <td>0.177698</td>\n",
       "      <td>-0.159124</td>\n",
       "      <td>-0.165513</td>\n",
       "      <td>-0.559997</td>\n",
       "      <td>0.153371</td>\n",
       "      <td>-0.333992</td>\n",
       "      <td>-0.425397</td>\n",
       "      <td>-0.305514</td>\n",
       "      <td>-0.170967</td>\n",
       "      <td>0.031572</td>\n",
       "      <td>0.138557</td>\n",
       "      <td>0.118684</td>\n",
       "      <td>0.082152</td>\n",
       "      <td>-0.585153</td>\n",
       "      <td>0.406673</td>\n",
       "      <td>0.312473</td>\n",
       "      <td>-0.185027</td>\n",
       "      <td>-0.180811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592306</th>\n",
       "      <td>1570.035200</td>\n",
       "      <td>1838.599017</td>\n",
       "      <td>15.483712</td>\n",
       "      <td>-1.772993</td>\n",
       "      <td>1.485489</td>\n",
       "      <td>0.392773</td>\n",
       "      <td>-1.326895</td>\n",
       "      <td>0.203322</td>\n",
       "      <td>-0.108285</td>\n",
       "      <td>-0.113250</td>\n",
       "      <td>-0.141969</td>\n",
       "      <td>-0.310526</td>\n",
       "      <td>-3.409197</td>\n",
       "      <td>-2.777020</td>\n",
       "      <td>-1.569631</td>\n",
       "      <td>-0.193509</td>\n",
       "      <td>-0.997573</td>\n",
       "      <td>-0.807044</td>\n",
       "      <td>-0.165214</td>\n",
       "      <td>-0.074524</td>\n",
       "      <td>-0.014452</td>\n",
       "      <td>-0.052748</td>\n",
       "      <td>0.027151</td>\n",
       "      <td>0.422977</td>\n",
       "      <td>0.754466</td>\n",
       "      <td>-0.258362</td>\n",
       "      <td>-0.219672</td>\n",
       "      <td>-0.386010</td>\n",
       "      <td>-0.369264</td>\n",
       "      <td>0.060509</td>\n",
       "      <td>-0.232003</td>\n",
       "      <td>0.156227</td>\n",
       "      <td>0.178212</td>\n",
       "      <td>-0.164480</td>\n",
       "      <td>-0.196227</td>\n",
       "      <td>-0.583570</td>\n",
       "      <td>-0.050938</td>\n",
       "      <td>-0.257679</td>\n",
       "      <td>-0.450286</td>\n",
       "      <td>-0.351557</td>\n",
       "      <td>-0.199204</td>\n",
       "      <td>-0.054291</td>\n",
       "      <td>0.085845</td>\n",
       "      <td>-0.231116</td>\n",
       "      <td>-0.079747</td>\n",
       "      <td>0.021328</td>\n",
       "      <td>-0.092450</td>\n",
       "      <td>-0.039104</td>\n",
       "      <td>-0.022430</td>\n",
       "      <td>-0.052356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231042</th>\n",
       "      <td>1581.139892</td>\n",
       "      <td>1810.713738</td>\n",
       "      <td>15.782918</td>\n",
       "      <td>-1.799413</td>\n",
       "      <td>1.501623</td>\n",
       "      <td>0.306342</td>\n",
       "      <td>-1.068746</td>\n",
       "      <td>0.087166</td>\n",
       "      <td>-0.188167</td>\n",
       "      <td>-0.091997</td>\n",
       "      <td>-0.167388</td>\n",
       "      <td>-0.200663</td>\n",
       "      <td>-3.611012</td>\n",
       "      <td>-2.961714</td>\n",
       "      <td>-1.213691</td>\n",
       "      <td>-0.193171</td>\n",
       "      <td>-1.117940</td>\n",
       "      <td>-0.832751</td>\n",
       "      <td>-0.153027</td>\n",
       "      <td>-0.083220</td>\n",
       "      <td>-0.007639</td>\n",
       "      <td>-0.052351</td>\n",
       "      <td>0.026848</td>\n",
       "      <td>0.427119</td>\n",
       "      <td>0.757563</td>\n",
       "      <td>-0.247715</td>\n",
       "      <td>-0.220266</td>\n",
       "      <td>-0.372189</td>\n",
       "      <td>-0.349727</td>\n",
       "      <td>0.059167</td>\n",
       "      <td>-0.230693</td>\n",
       "      <td>0.156107</td>\n",
       "      <td>0.182471</td>\n",
       "      <td>-0.166248</td>\n",
       "      <td>-0.197005</td>\n",
       "      <td>-0.593351</td>\n",
       "      <td>-0.049244</td>\n",
       "      <td>-0.284562</td>\n",
       "      <td>-0.457567</td>\n",
       "      <td>-0.344180</td>\n",
       "      <td>-0.216068</td>\n",
       "      <td>-0.067168</td>\n",
       "      <td>0.123558</td>\n",
       "      <td>-0.303916</td>\n",
       "      <td>-0.084047</td>\n",
       "      <td>0.012885</td>\n",
       "      <td>-0.092737</td>\n",
       "      <td>-0.029926</td>\n",
       "      <td>-0.021159</td>\n",
       "      <td>-0.088956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13184010 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pca0         pca1       pca2      pca3      pca4      pca5  \\\n",
       "237129    -854.833838   -22.350535  -2.076370  0.440297  0.167337 -0.572813   \n",
       "4084368   -854.834141   -22.338888  -1.070168 -0.928008  0.109072  0.652765   \n",
       "1029548    147.713096   -77.108846  -2.508873  0.219041  0.183271 -0.052362   \n",
       "11163145  -854.831051   -22.315751   0.932171 -1.247213  0.264628  0.378429   \n",
       "12079249  -119.476685   -38.252221  -0.403234 -0.088713  0.273856  0.885572   \n",
       "...               ...          ...        ...       ...       ...       ...   \n",
       "4840623   1446.920810  1804.960411  16.114719 -2.422619  1.610649  0.672875   \n",
       "3552614   1481.735235  1815.057061  15.927770 -1.738535  1.102894  0.766987   \n",
       "3919427   1548.791783  1824.509533  15.677436 -1.876378  1.746183  0.700656   \n",
       "592306    1570.035200  1838.599017  15.483712 -1.772993  1.485489  0.392773   \n",
       "231042    1581.139892  1810.713738  15.782918 -1.799413  1.501623  0.306342   \n",
       "\n",
       "              pca6      pca7      pca8      pca9     pca10     pca11  \\\n",
       "237129   -1.737709  1.939359  0.598997 -0.055869 -0.137670 -0.548254   \n",
       "4084368   1.616179 -0.338744  0.239957 -0.415272 -0.021180 -0.514327   \n",
       "1029548  -1.468815  0.891923  0.671056 -0.296954 -0.029719 -1.096354   \n",
       "11163145  1.092836 -0.747042 -0.019225 -0.376363 -0.005954 -0.375436   \n",
       "12079249 -0.906457 -0.789604  0.586895 -0.564328  0.173975 -1.293512   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "4840623   0.969259 -0.592852  0.183473 -0.746838  0.094900 -1.218365   \n",
       "3552614  -1.048087  0.406609  0.001147  0.025129 -0.039639  0.033922   \n",
       "3919427  -1.643239  0.711923  0.211755 -0.202342  0.123060 -0.448522   \n",
       "592306   -1.326895  0.203322 -0.108285 -0.113250 -0.141969 -0.310526   \n",
       "231042   -1.068746  0.087166 -0.188167 -0.091997 -0.167388 -0.200663   \n",
       "\n",
       "             pca12     pca13     pca14     pca15     pca16     pca17  \\\n",
       "237129   -0.542312  0.298613  2.088348  0.848927 -0.670052  0.047257   \n",
       "4084368   1.026836 -0.051468  0.161360 -0.747007  0.014852 -0.861847   \n",
       "1029548  -0.770653 -0.639487  0.545767 -0.418540 -0.463175  0.530344   \n",
       "11163145 -0.156368  0.354747 -0.050449 -0.307445 -0.060767 -0.807887   \n",
       "12079249 -1.045807 -0.493408  0.800315 -0.377958 -0.731310  0.488236   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "4840623   0.083777  0.472713  0.095803 -1.852203  1.153305  0.728748   \n",
       "3552614  -1.720980 -0.440556  1.980514 -0.355618 -1.014802  0.132178   \n",
       "3919427  -1.297856 -0.692133  1.638966 -0.015737 -1.040638  0.249941   \n",
       "592306   -3.409197 -2.777020 -1.569631 -0.193509 -0.997573 -0.807044   \n",
       "231042   -3.611012 -2.961714 -1.213691 -0.193171 -1.117940 -0.832751   \n",
       "\n",
       "             pca18     pca19     pca20     pca21     pca22     pca23  \\\n",
       "237129    0.212088 -0.128773 -0.051730 -0.342995  0.748262 -0.345468   \n",
       "4084368  -0.250895 -0.119135 -0.133813 -0.564526 -0.642091 -0.424731   \n",
       "1029548   0.035675 -0.098316 -0.162530 -0.570328 -0.655989 -0.407679   \n",
       "11163145 -0.260028 -0.295990 -0.442526  0.695511 -0.105206 -0.350451   \n",
       "12079249  0.055338 -0.272298 -0.448355  0.696611 -0.107243 -0.339225   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "4840623   0.041038 -0.053026  0.011305 -0.055739  0.029012  0.410431   \n",
       "3552614  -0.074262 -0.259097  0.046958 -0.056985 -0.000113  0.344622   \n",
       "3919427   0.238326  0.004336 -0.026771 -0.041061  0.009652  0.485591   \n",
       "592306   -0.165214 -0.074524 -0.014452 -0.052748  0.027151  0.422977   \n",
       "231042   -0.153027 -0.083220 -0.007639 -0.052351  0.026848  0.427119   \n",
       "\n",
       "             pca24     pca25     pca26     pca27     pca28     pca29  \\\n",
       "237129   -0.041718  0.132528 -0.142064  0.022071 -0.059568  0.017391   \n",
       "4084368  -0.075788 -0.197131 -0.176772 -0.352992 -0.315177 -0.040223   \n",
       "1029548  -0.078887 -0.174331 -0.140635 -0.348590 -0.346866 -0.048655   \n",
       "11163145 -0.069121 -0.235673 -0.162171 -0.369080 -0.373825 -0.024298   \n",
       "12079249 -0.062423 -0.195257 -0.137837 -0.358293 -0.378293 -0.034077   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "4840623   0.748450 -0.466618 -0.281612 -0.387750 -0.185651  0.043890   \n",
       "3552614   0.708491 -0.775352 -0.352902 -0.731150 -0.293085  0.061118   \n",
       "3919427   0.788253 -0.008662 -0.209193  0.100622  0.095191  0.042284   \n",
       "592306    0.754466 -0.258362 -0.219672 -0.386010 -0.369264  0.060509   \n",
       "231042    0.757563 -0.247715 -0.220266 -0.372189 -0.349727  0.059167   \n",
       "\n",
       "             pca30     pca31     pca32     pca33     pca34     pca35  \\\n",
       "237129   -0.065895 -0.026877  0.021622 -0.050331  0.102271 -0.066844   \n",
       "4084368  -0.038654  0.016543 -0.037551 -0.054355  0.055144 -0.039692   \n",
       "1029548  -0.071341 -0.003489 -0.006502 -0.044877  0.046853 -0.069222   \n",
       "11163145 -0.026886 -0.015455 -0.058525 -0.081886  0.080335 -0.052614   \n",
       "12079249 -0.053095 -0.025850 -0.046371 -0.087511  0.072096 -0.073661   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "4840623  -0.232125  0.200536  0.158804 -0.229552 -0.207657 -0.536611   \n",
       "3552614  -0.207876  0.194648  0.166185 -0.225491 -0.233954 -0.589453   \n",
       "3919427  -0.231527  0.149686  0.177698 -0.159124 -0.165513 -0.559997   \n",
       "592306   -0.232003  0.156227  0.178212 -0.164480 -0.196227 -0.583570   \n",
       "231042   -0.230693  0.156107  0.182471 -0.166248 -0.197005 -0.593351   \n",
       "\n",
       "             pca36     pca37     pca38     pca39     pca40     pca41  \\\n",
       "237129    0.130475  0.551934  0.570553 -0.210321 -0.257098  0.002678   \n",
       "4084368  -0.116110  0.300608 -0.405332  0.724086 -0.120801 -0.010670   \n",
       "1029548  -0.125848  0.334864 -0.390163  0.723194 -0.134809  0.043661   \n",
       "11163145 -0.108992  0.310271 -0.403620  0.745579 -0.123430 -0.017223   \n",
       "12079249 -0.109357  0.314965 -0.391231  0.759849 -0.127114  0.031212   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "4840623  -0.010809 -0.290260 -0.307992 -0.237195 -0.266611  0.054686   \n",
       "3552614  -0.242532 -0.328401 -0.386488 -0.269394 -0.055422  0.010671   \n",
       "3919427   0.153371 -0.333992 -0.425397 -0.305514 -0.170967  0.031572   \n",
       "592306   -0.050938 -0.257679 -0.450286 -0.351557 -0.199204 -0.054291   \n",
       "231042   -0.049244 -0.284562 -0.457567 -0.344180 -0.216068 -0.067168   \n",
       "\n",
       "             pca42     pca43     pca44     pca45     pca46     pca47  \\\n",
       "237129    0.173589 -0.273864 -0.091286  0.039982 -0.003104 -0.021177   \n",
       "4084368   0.046517 -0.184143 -0.035533 -0.030640  0.081651 -0.096209   \n",
       "1029548   0.057495 -0.173647 -0.040443  0.051205  0.059454 -0.133284   \n",
       "11163145  0.049851 -0.204998 -0.022656 -0.019727  0.065002 -0.089580   \n",
       "12079249  0.063480 -0.202389 -0.007835  0.036338  0.045206 -0.129339   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "4840623   0.025843 -0.122352 -0.085951 -0.067543  0.059791 -0.030700   \n",
       "3552614   0.013124 -0.213789  0.007008 -0.020031 -0.065807 -0.036923   \n",
       "3919427   0.138557  0.118684  0.082152 -0.585153  0.406673  0.312473   \n",
       "592306    0.085845 -0.231116 -0.079747  0.021328 -0.092450 -0.039104   \n",
       "231042    0.123558 -0.303916 -0.084047  0.012885 -0.092737 -0.029926   \n",
       "\n",
       "             pca48     pca49  \n",
       "237129   -0.032929  0.007210  \n",
       "4084368  -0.106677  0.052260  \n",
       "1029548   0.035110  0.017812  \n",
       "11163145 -0.117794  0.048885  \n",
       "12079249  0.028349  0.012828  \n",
       "...            ...       ...  \n",
       "4840623   0.073462 -0.044373  \n",
       "3552614   0.014594 -0.126170  \n",
       "3919427  -0.185027 -0.180811  \n",
       "592306   -0.022430 -0.052356  \n",
       "231042   -0.021159 -0.088956  \n",
       "\n",
       "[13184010 rows x 50 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the pipeline in this cell and run it on X, this cell must end with the transformed data\n",
    "X = preprocessor.fit_transform(X_train, y_train)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the preprocessor as a parquet file\n",
    "X.to_parquet(\"preprocessor.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"preprocessor.pkl\", \"wb\") as f:\n",
    "    pickle.dump(preprocessor, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_logger <class '__main__.ProgressLogger'> 48\n",
      "delay_trend <class '__main__.DelayTrendEncoder'> 48\n",
      "trend_logger <class '__main__.ProgressLogger'> 48\n",
      "tail_reuse <class '__main__.SameDayTailReuseEncoder'> 48\n",
      "reuse_logger <class '__main__.ProgressLogger'> 48\n",
      "turnaround_delay <class '__main__.TurnaroundDelayEncoder'> 48\n",
      "turnaround_logger <class '__main__.ProgressLogger'> 48\n",
      "slack_time <class '__main__.SlackTimeEncoder'> 48\n",
      "slack_logger <class '__main__.ProgressLogger'> 48\n",
      "feature_prep <class 'sklearn.compose._column_transformer.ColumnTransformer'> 48\n",
      "prep_logger <class '__main__.ProgressLogger'> 48\n",
      "select <class 'sklearn.feature_selection._from_model.SelectFromModel'> 48\n",
      "final_logger <class '__main__.ProgressLogger'> 48\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "for name, step in preprocessor.named_steps.items():\n",
    "    print(name, type(step), sys.getsizeof(step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, precision_score, recall_score, precision_recall_curve\n",
    "def precision_at_recall(y, y_pred, *, recall, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate the precision at a given recall level.\n",
    "\n",
    "    To use this with cross_val_score, you need to use the make_scorer function to\n",
    "    create a scoring function that can be used with cross_val_score. For example:\n",
    "\n",
    "        scorer = make_scorer(precision_at_recall, recall=0.9)  # 0.9 is the minimum recall level\n",
    "        cross_val_score(model, X, y, cv=5, scoring=scorer)\n",
    "\n",
    "    The default will only work for binary classification problems. You must change the\n",
    "    average parameter if you want to use for multiclass classification. For example:\n",
    "\n",
    "        scorer = make_scorer(precision_at_recall, recall=0.9, average=\"micro\")\n",
    "    \"\"\"\n",
    "    return precision_score(y, y_pred, **kwargs) if recall_score(y, y_pred, **kwargs) > recall else 0.0\n",
    "\n",
    "def recall_at_precision(y, y_pred, *, precision, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate the recall at a given precision level.\n",
    "\n",
    "    To use this with cross_val_score, you need to use the make_scorer function to\n",
    "    create a scoring function that can be used with cross_val_score. For example:\n",
    "\n",
    "        scorer = make_scorer(recall_at_precision, precision=0.9)\n",
    "        cross_val_score(model, X, y, cv=5, scoring=scorer)\n",
    "\n",
    "    The default will only work for binary classification problems. You must change the\n",
    "    average parameter if you want to use for multiclass classification. For example:\n",
    "\n",
    "        scorer = make_scorer(recall_at_precision, precision=0.9, average=\"micro\")\n",
    "    \"\"\"\n",
    "    return recall_score(y, y_pred, **kwargs) if precision_score(y, y_pred, **kwargs) > precision else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_sample = X # .sample(n=100000, random_state=42)\n",
    "y_train = y_train.sample(n=100000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:   19.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0520\n",
      "Precision: 0.0549\n",
      "F1 Score: 0.0131\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.00      0.14      0.01       424\n",
      "      Major Delay - CarrierDelay       0.01      0.11      0.01       514\n",
      " Major Delay - LateAircraftDelay       0.01      0.12      0.01       649\n",
      "          Major Delay - NASDelay       0.00      0.01      0.00        91\n",
      "      Major Delay - WeatherDelay       0.00      0.06      0.00        96\n",
      "     Medium Delay - CarrierDelay       0.02      0.06      0.03      1881\n",
      "Medium Delay - LateAircraftDelay       0.03      0.02      0.03      2886\n",
      "         Medium Delay - NASDelay       0.00      0.11      0.01       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.05      0.01       325\n",
      "      Minor Delay - CarrierDelay       0.03      0.03      0.03      3539\n",
      " Minor Delay - LateAircraftDelay       0.04      0.02      0.02      4238\n",
      "          Minor Delay - NASDelay       0.01      0.03      0.01      1060\n",
      "      Minor Delay - WeatherDelay       0.00      0.06      0.01       326\n",
      "                NAS Cancellation       0.00      0.07      0.00       205\n",
      "                         On-Time       0.78      0.01      0.02     78470\n",
      "                  Security Issue       0.00      0.00      0.00        51\n",
      "                         Unknown       0.04      0.02      0.03      3977\n",
      "            Weather Cancellation       0.01      0.03      0.01       781\n",
      "\n",
      "                        accuracy                           0.01    100000\n",
      "                       macro avg       0.05      0.05      0.01    100000\n",
      "                    weighted avg       0.62      0.01      0.02    100000\n",
      "\n",
      "Mean precision at recall 0.2: 0.0000 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=20,\n",
    "    min_samples_leaf=10,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "scorer = make_scorer(precision_at_recall, recall=0.2, average='weighted')\n",
    "\n",
    "scores = cross_val_score(dt, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "y_pred_cv = cross_val_predict(dt, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flight_Status\n",
       "On-Time                             78470\n",
       "Minor Delay - LateAircraftDelay      4238\n",
       "Unknown                              3977\n",
       "Minor Delay - CarrierDelay           3539\n",
       "Medium Delay - LateAircraftDelay     2886\n",
       "Medium Delay - CarrierDelay          1881\n",
       "Minor Delay - NASDelay               1060\n",
       "Weather Cancellation                  781\n",
       "Major Delay - LateAircraftDelay       649\n",
       "Major Delay - CarrierDelay            514\n",
       "Medium Delay - NASDelay               487\n",
       "Carrier Cancellation                  424\n",
       "Minor Delay - WeatherDelay            326\n",
       "Medium Delay - WeatherDelay           325\n",
       "NAS Cancellation                      205\n",
       "Major Delay - WeatherDelay             96\n",
       "Major Delay - NASDelay                 91\n",
       "Security Issue                         51\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0556\n",
      "Precision: 0.0482\n",
      "F1 Score: 0.0494\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.03      0.00      0.00       424\n",
      "      Major Delay - CarrierDelay       0.02      0.00      0.00       514\n",
      " Major Delay - LateAircraftDelay       0.00      0.00      0.00       649\n",
      "          Major Delay - NASDelay       0.00      0.00      0.00        91\n",
      "      Major Delay - WeatherDelay       0.00      0.00      0.00        96\n",
      "     Medium Delay - CarrierDelay       0.00      0.00      0.00      1881\n",
      "Medium Delay - LateAircraftDelay       0.00      0.00      0.00      2886\n",
      "         Medium Delay - NASDelay       0.03      0.00      0.00       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.00      0.00       325\n",
      "      Minor Delay - CarrierDelay       0.00      0.00      0.00      3539\n",
      " Minor Delay - LateAircraftDelay       0.00      0.00      0.00      4238\n",
      "          Minor Delay - NASDelay       0.00      0.00      0.00      1060\n",
      "      Minor Delay - WeatherDelay       0.00      0.00      0.00       326\n",
      "                NAS Cancellation       0.00      0.00      0.00       205\n",
      "                         On-Time       0.78      0.99      0.88     78470\n",
      "                  Security Issue       0.00      0.00      0.00        51\n",
      "                         Unknown       0.00      0.00      0.00      3977\n",
      "            Weather Cancellation       0.00      0.00      0.00       781\n",
      "\n",
      "                        accuracy                           0.78    100000\n",
      "                       macro avg       0.05      0.06      0.05    100000\n",
      "                    weighted avg       0.62      0.78      0.69    100000\n",
      "\n",
      "Mean precision at recall 0.2: 0.6161 ± 0.0006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=20,    \n",
    "    max_depth=3,        \n",
    "    learning_rate=0.1,  \n",
    "    subsample=0.6,       \n",
    "    random_state=42,\n",
    "    verbose=2            \n",
    ")\n",
    "\n",
    "scorer = make_scorer(precision_at_recall, recall=0.2, average='weighted')\n",
    "\n",
    "scores = cross_val_score(model, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "y_pred_cv = cross_val_predict(model, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:   29.8s finished\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0555\n",
      "Precision: 0.0436\n",
      "F1 Score: 0.0488\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.00      0.00      0.00       424\n",
      "      Major Delay - CarrierDelay       0.00      0.00      0.00       514\n",
      " Major Delay - LateAircraftDelay       0.00      0.00      0.00       649\n",
      "          Major Delay - NASDelay       0.00      0.00      0.00        91\n",
      "      Major Delay - WeatherDelay       0.00      0.00      0.00        96\n",
      "     Medium Delay - CarrierDelay       0.00      0.00      0.00      1881\n",
      "Medium Delay - LateAircraftDelay       0.00      0.00      0.00      2886\n",
      "         Medium Delay - NASDelay       0.00      0.00      0.00       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.00      0.00       325\n",
      "      Minor Delay - CarrierDelay       0.00      0.00      0.00      3539\n",
      " Minor Delay - LateAircraftDelay       0.00      0.00      0.00      4238\n",
      "          Minor Delay - NASDelay       0.00      0.00      0.00      1060\n",
      "      Minor Delay - WeatherDelay       0.00      0.00      0.00       326\n",
      "                NAS Cancellation       0.00      0.00      0.00       205\n",
      "                         On-Time       0.78      1.00      0.88     78470\n",
      "                  Security Issue       0.00      0.00      0.00        51\n",
      "                         Unknown       0.00      0.00      0.00      3977\n",
      "            Weather Cancellation       0.00      0.00      0.00       781\n",
      "\n",
      "                        accuracy                           0.78    100000\n",
      "                       macro avg       0.04      0.06      0.05    100000\n",
      "                    weighted avg       0.62      0.78      0.69    100000\n",
      "\n",
      "Mean precision at recall 0.2: 0.6158 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_classifier = SGDClassifier(\n",
    "    loss='log_loss',     \n",
    "    alpha=0.0001,   \n",
    "    n_jobs=64,\n",
    "    random_state=42       \n",
    ")\n",
    "\n",
    "scorer = make_scorer(precision_at_recall, recall=0.2, average='weighted')\n",
    "\n",
    "scores = cross_val_score(sgd_classifier, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "y_pred_cv = cross_val_predict(sgd_classifier, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  4.52906D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  5.08173D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  5.06678D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  6.82702D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  4.50830D+05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.30413D+05    |proj g|=  1.83678D+04\n",
      "\n",
      "At iterate   50    f=  2.30460D+05    |proj g|=  7.64161D+03\n",
      "\n",
      "At iterate   50    f=  2.30432D+05    |proj g|=  2.04515D+04\n",
      "\n",
      "At iterate   50    f=  2.30363D+05    |proj g|=  3.13326D+04\n",
      "\n",
      "At iterate   50    f=  2.30345D+05    |proj g|=  1.77993D+05\n",
      "\n",
      "At iterate  100    f=  2.29901D+05    |proj g|=  6.31362D+04\n",
      "\n",
      "At iterate  100    f=  2.29820D+05    |proj g|=  1.75573D+04\n",
      "\n",
      "At iterate  100    f=  2.30006D+05    |proj g|=  7.56836D+04\n",
      "\n",
      "At iterate  100    f=  2.29745D+05    |proj g|=  3.66572D+04\n",
      "\n",
      "At iterate  100    f=  2.29718D+05    |proj g|=  9.28460D+04\n",
      "\n",
      "At iterate  150    f=  2.28940D+05    |proj g|=  2.57050D+04\n",
      "\n",
      "At iterate  150    f=  2.29335D+05    |proj g|=  4.78086D+04\n",
      "\n",
      "At iterate  150    f=  2.29303D+05    |proj g|=  1.39796D+04\n",
      "\n",
      "At iterate  150    f=  2.29740D+05    |proj g|=  2.78229D+04\n",
      "\n",
      "At iterate  150    f=  2.29359D+05    |proj g|=  1.66245D+04\n",
      "\n",
      "At iterate  200    f=  2.28725D+05    |proj g|=  8.22377D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    211      1     0     0   8.224D+04   2.287D+05\n",
      "  F =   228724.81232402046     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "\n",
      "At iterate  200    f=  2.28655D+05    |proj g|=  1.18179D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    210      1     0     0   1.182D+04   2.287D+05\n",
      "  F =   228655.09423526545     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   10.8s finished\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   10.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate  200    f=  2.28091D+05    |proj g|=  5.04936D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    214      1     0     0   5.049D+04   2.281D+05\n",
      "  F =   228091.21236615849     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "\n",
      "At iterate  200    f=  2.29113D+05    |proj g|=  3.50903D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    213      1     0     0   3.509D+04   2.291D+05\n",
      "  F =   229113.05220798624     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   11.1s finished\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   11.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate  200    f=  2.28640D+05    |proj g|=  1.39139D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    217      1     0     0   1.391D+04   2.286D+05\n",
      "  F =   228639.94628400612     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   11.3s finished\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:   12.8s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  5.08173D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  5.06678D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  4.50830D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  4.52906D+05\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          918     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31230D+05    |proj g|=  6.82702D+05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.30345D+05    |proj g|=  1.77993D+05\n",
      "\n",
      "At iterate   50    f=  2.30432D+05    |proj g|=  2.04515D+04\n",
      "\n",
      "At iterate   50    f=  2.30460D+05    |proj g|=  7.64161D+03\n",
      "\n",
      "At iterate   50    f=  2.30413D+05    |proj g|=  1.83678D+04\n",
      "\n",
      "At iterate   50    f=  2.30363D+05    |proj g|=  3.13326D+04\n",
      "\n",
      "At iterate  100    f=  2.29718D+05    |proj g|=  9.28460D+04\n",
      "\n",
      "At iterate  100    f=  2.29820D+05    |proj g|=  1.75573D+04\n",
      "\n",
      "At iterate  100    f=  2.30006D+05    |proj g|=  7.56836D+04\n",
      "\n",
      "At iterate  100    f=  2.29901D+05    |proj g|=  6.31362D+04\n",
      "\n",
      "At iterate  100    f=  2.29745D+05    |proj g|=  3.66572D+04\n",
      "\n",
      "At iterate  150    f=  2.29303D+05    |proj g|=  1.39796D+04\n",
      "\n",
      "At iterate  150    f=  2.29359D+05    |proj g|=  1.66245D+04\n",
      "\n",
      "At iterate  150    f=  2.29740D+05    |proj g|=  2.78229D+04\n",
      "\n",
      "At iterate  150    f=  2.29335D+05    |proj g|=  4.78086D+04\n",
      "\n",
      "At iterate  150    f=  2.28940D+05    |proj g|=  2.57050D+04\n",
      "\n",
      "At iterate  200    f=  2.28655D+05    |proj g|=  1.18179D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    210      1     0     0   1.182D+04   2.287D+05\n",
      "  F =   228655.09423526545     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   10.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate  200    f=  2.29113D+05    |proj g|=  3.50903D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    213      1     0     0   3.509D+04   2.291D+05\n",
      "  F =   229113.05220798624     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "\n",
      "At iterate  200    f=  2.28640D+05    |proj g|=  1.39139D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    217      1     0     0   1.391D+04   2.286D+05\n",
      "  F =   228639.94628400612     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   11.7s finished\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   11.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate  200    f=  2.28725D+05    |proj g|=  8.22377D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    211      1     0     0   8.224D+04   2.287D+05\n",
      "  F =   228724.81232402046     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   12.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate  200    f=  2.28091D+05    |proj g|=  5.04936D+04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  918    200    214      1     0     0   5.049D+04   2.281D+05\n",
      "  F =   228091.21236615849     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=64)]: Done   1 out of   1 | elapsed:   12.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0682\n",
      "Precision: 0.0681\n",
      "F1 Score: 0.0058\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.00      0.04      0.01       424\n",
      "      Major Delay - CarrierDelay       0.01      0.07      0.01       514\n",
      " Major Delay - LateAircraftDelay       0.00      0.00      0.00       649\n",
      "          Major Delay - NASDelay       0.00      0.10      0.00        91\n",
      "      Major Delay - WeatherDelay       0.00      0.27      0.00        96\n",
      "     Medium Delay - CarrierDelay       0.04      0.00      0.01      1881\n",
      "Medium Delay - LateAircraftDelay       0.04      0.01      0.01      2886\n",
      "         Medium Delay - NASDelay       0.00      0.05      0.01       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.05      0.01       325\n",
      "      Minor Delay - CarrierDelay       0.03      0.00      0.00      3539\n",
      " Minor Delay - LateAircraftDelay       0.04      0.00      0.00      4238\n",
      "          Minor Delay - NASDelay       0.02      0.02      0.02      1060\n",
      "      Minor Delay - WeatherDelay       0.00      0.02      0.01       326\n",
      "                NAS Cancellation       0.00      0.10      0.00       205\n",
      "                         On-Time       1.00      0.00      0.00     78470\n",
      "                  Security Issue       0.00      0.45      0.00        51\n",
      "                         Unknown       0.02      0.00      0.00      3977\n",
      "            Weather Cancellation       0.01      0.03      0.01       781\n",
      "\n",
      "                        accuracy                           0.00    100000\n",
      "                       macro avg       0.07      0.07      0.01    100000\n",
      "                    weighted avg       0.79      0.00      0.00    100000\n",
      "\n",
      "Mean precision at recall 0.2: 0.0000 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=1.0,                 \n",
    "    max_iter=200,        \n",
    "    tol=1e-3,           \n",
    "    class_weight='balanced', \n",
    "    n_jobs=64,          \n",
    "    random_state=42,     \n",
    "    verbose=1            \n",
    ")\n",
    "\n",
    "scores = cross_val_score(log_reg, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "y_pred_cv = cross_val_predict(log_reg, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:   22.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0556\n",
      "Precision: 0.0571\n",
      "F1 Score: 0.0489\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.00      0.00      0.00       424\n",
      "      Major Delay - CarrierDelay       0.00      0.00      0.00       514\n",
      " Major Delay - LateAircraftDelay       0.00      0.00      0.00       649\n",
      "          Major Delay - NASDelay       0.00      0.00      0.00        91\n",
      "      Major Delay - WeatherDelay       0.00      0.00      0.00        96\n",
      "     Medium Delay - CarrierDelay       0.00      0.00      0.00      1881\n",
      "Medium Delay - LateAircraftDelay       0.00      0.00      0.00      2886\n",
      "         Medium Delay - NASDelay       0.00      0.00      0.00       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.00      0.00       325\n",
      "      Minor Delay - CarrierDelay       0.00      0.00      0.00      3539\n",
      " Minor Delay - LateAircraftDelay       0.17      0.00      0.00      4238\n",
      "          Minor Delay - NASDelay       0.00      0.00      0.00      1060\n",
      "      Minor Delay - WeatherDelay       0.00      0.00      0.00       326\n",
      "                NAS Cancellation       0.00      0.00      0.00       205\n",
      "                         On-Time       0.78      1.00      0.88     78470\n",
      "                  Security Issue       0.00      0.00      0.00        51\n",
      "                         Unknown       0.08      0.00      0.00      3977\n",
      "            Weather Cancellation       0.00      0.00      0.00       781\n",
      "\n",
      "                        accuracy                           0.78    100000\n",
      "                       macro avg       0.06      0.06      0.05    100000\n",
      "                    weighted avg       0.63      0.78      0.69    100000\n",
      "\n",
      "Mean precision at recall 0.2: 0.6195 ± 0.0055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, precision_score\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100),\n",
    "    max_iter=100,              \n",
    "    early_stopping=True,\n",
    "    random_state=42            \n",
    ")\n",
    "\n",
    "scorer = make_scorer(precision_at_recall, recall=0.2, average='weighted')\n",
    "\n",
    "scores = cross_val_score(mlp, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "y_pred_cv = cross_val_predict(mlp, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.6s remaining:    2.7s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.6s remaining:    2.7s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.7s remaining:    2.7s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.9s remaining:    2.8s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    8.1s remaining:    2.8s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.4s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.6s finished\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.6s finished\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.6s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:   10.6s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.1s remaining:    2.5s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.5s remaining:    2.6s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.5s remaining:    2.6s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.6s remaining:    2.7s\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    7.8s remaining:    2.8s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.1s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.2s finished\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=64)]: Using backend ThreadingBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=64)]: Done  74 out of 100 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=64)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0564\n",
      "Precision: 0.0559\n",
      "F1 Score: 0.0523\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.00      0.01      0.01       424\n",
      "      Major Delay - CarrierDelay       0.01      0.01      0.01       514\n",
      " Major Delay - LateAircraftDelay       0.01      0.02      0.01       649\n",
      "          Major Delay - NASDelay       0.00      0.00      0.00        91\n",
      "      Major Delay - WeatherDelay       0.00      0.00      0.00        96\n",
      "     Medium Delay - CarrierDelay       0.02      0.04      0.03      1881\n",
      "Medium Delay - LateAircraftDelay       0.03      0.06      0.04      2886\n",
      "         Medium Delay - NASDelay       0.01      0.02      0.01       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.01      0.01       325\n",
      "      Minor Delay - CarrierDelay       0.04      0.07      0.05      3539\n",
      " Minor Delay - LateAircraftDelay       0.04      0.08      0.05      4238\n",
      "          Minor Delay - NASDelay       0.01      0.03      0.02      1060\n",
      "      Minor Delay - WeatherDelay       0.01      0.02      0.01       326\n",
      "                NAS Cancellation       0.00      0.00      0.00       205\n",
      "                         On-Time       0.79      0.54      0.64     78470\n",
      "                  Security Issue       0.00      0.00      0.00        51\n",
      "                         Unknown       0.04      0.08      0.05      3977\n",
      "            Weather Cancellation       0.01      0.01      0.01       781\n",
      "\n",
      "                        accuracy                           0.44    100000\n",
      "                       macro avg       0.06      0.06      0.05    100000\n",
      "                    weighted avg       0.62      0.44      0.51    100000\n",
      "\n",
      "Mean precision at recall 0.2: 0.6231 ± 0.0013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,        \n",
    "    max_depth=15,            \n",
    "    min_samples_split=10,    \n",
    "    min_samples_leaf=5,     \n",
    "    max_features='sqrt',     \n",
    "    bootstrap=True,          \n",
    "    class_weight='balanced', \n",
    "    n_jobs=64,              \n",
    "    random_state=42,         \n",
    "    verbose=1               \n",
    ")\n",
    "\n",
    "scorer = make_scorer(precision_at_recall, recall=0.2, average='weighted')\n",
    "\n",
    "scores = cross_val_score(rf, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "y_pred_cv = cross_val_predict(rf, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:   12.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0560\n",
      "Precision: 0.0589\n",
      "F1 Score: 0.0513\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.00      0.00      0.00       424\n",
      "      Major Delay - CarrierDelay       0.00      0.00      0.00       514\n",
      " Major Delay - LateAircraftDelay       0.00      0.00      0.00       649\n",
      "          Major Delay - NASDelay       0.00      0.00      0.00        91\n",
      "      Major Delay - WeatherDelay       0.10      0.01      0.02        96\n",
      "     Medium Delay - CarrierDelay       0.02      0.00      0.00      1881\n",
      "Medium Delay - LateAircraftDelay       0.02      0.00      0.00      2886\n",
      "         Medium Delay - NASDelay       0.00      0.00      0.00       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.00      0.00       325\n",
      "      Minor Delay - CarrierDelay       0.03      0.00      0.01      3539\n",
      " Minor Delay - LateAircraftDelay       0.05      0.01      0.01      4238\n",
      "          Minor Delay - NASDelay       0.00      0.00      0.00      1060\n",
      "      Minor Delay - WeatherDelay       0.00      0.00      0.00       326\n",
      "                NAS Cancellation       0.00      0.00      0.00       205\n",
      "                         On-Time       0.78      0.98      0.87     78470\n",
      "                  Security Issue       0.00      0.00      0.00        51\n",
      "                         Unknown       0.04      0.00      0.01      3977\n",
      "            Weather Cancellation       0.03      0.00      0.00       781\n",
      "\n",
      "                        accuracy                           0.77    100000\n",
      "                       macro avg       0.06      0.06      0.05    100000\n",
      "                    weighted avg       0.62      0.77      0.68    100000\n",
      "\n",
      "Mean precision at recall 0.2: 0.6217 ± 0.0022\n"
     ]
    }
   ],
   "source": [
    "# KNN configuration\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=5,   \n",
    "    weights='distance', \n",
    "    n_jobs=64           \n",
    ")\n",
    "\n",
    "\n",
    "scorer = make_scorer(precision_at_recall, recall=0.2, average='weighted')\n",
    "\n",
    "scores = cross_val_score(knn, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "y_pred_cv = cross_val_predict(knn, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=64)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=64)]: Done   5 out of   5 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0566\n",
      "Precision: 0.0560\n",
      "F1 Score: 0.0548\n",
      "Cross-Validation Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.00      0.00      0.00       424\n",
      "      Major Delay - CarrierDelay       0.01      0.01      0.01       514\n",
      " Major Delay - LateAircraftDelay       0.00      0.00      0.00       649\n",
      "          Major Delay - NASDelay       0.00      0.00      0.00        91\n",
      "      Major Delay - WeatherDelay       0.01      0.02      0.01        96\n",
      "     Medium Delay - CarrierDelay       0.02      0.01      0.01      1881\n",
      "Medium Delay - LateAircraftDelay       0.03      0.01      0.02      2886\n",
      "         Medium Delay - NASDelay       0.01      0.01      0.01       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.00      0.00       325\n",
      "      Minor Delay - CarrierDelay       0.04      0.02      0.02      3539\n",
      " Minor Delay - LateAircraftDelay       0.04      0.02      0.02      4238\n",
      "          Minor Delay - NASDelay       0.01      0.01      0.01      1060\n",
      "      Minor Delay - WeatherDelay       0.00      0.00      0.00       326\n",
      "                NAS Cancellation       0.00      0.00      0.00       205\n",
      "                         On-Time       0.78      0.90      0.84     78470\n",
      "                  Security Issue       0.00      0.00      0.00        51\n",
      "                         Unknown       0.04      0.02      0.02      3977\n",
      "            Weather Cancellation       0.00      0.00      0.00       781\n",
      "\n",
      "                        accuracy                           0.71    100000\n",
      "                       macro avg       0.06      0.06      0.05    100000\n",
      "                    weighted avg       0.62      0.71      0.66    100000\n",
      "\n",
      "Mean precision at recall 0.2: 0.6218 ± 0.0013\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0042          -0.0317            6.95m\n",
      "         2           1.0081      -40138.2895            6.27m\n",
      "         3       26759.8696       40138.2951            5.82m\n",
      "         4       26759.8875        -121.8885            5.44m\n",
      "         5           1.0818  -415411197.7708            5.07m\n",
      "         6   276940799.5580   415411197.7211            4.72m\n",
      "         7   276940880.8312         121.9090            4.37m\n",
      "         8   276940880.8185          -0.0142            4.02m\n",
      "         9       26841.2141  -415371063.1719            3.68m\n",
      "        10       26843.7205           3.7629            3.34m\n",
      "        11   276914121.9561   415330917.3110            3.00m\n",
      "        12       26843.6908  -415330917.3881            2.66m\n",
      "        13   276940880.8633   415371055.7658            2.33m\n",
      "        14   276940880.8772           0.0149            1.99m\n",
      "        15       26843.7076  -415371055.7526            1.66m\n",
      "        16           3.5668      -40260.2077            1.33m\n",
      "        17          84.9036         122.0118           59.70s\n",
      "        18   276914121.8809   415371055.4643           39.77s\n",
      "        19           3.5674  -415371177.4653           19.87s\n",
      "        20          84.8314         121.8969            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0043          -0.0376            6.43m\n",
      "         2           1.0049           0.0037            5.99m\n",
      "         3           1.0078          -0.0048            5.62m\n",
      "         4           1.0222     -278407.6737            5.28m\n",
      "         5      185606.0684   -12775237.3040            4.94m\n",
      "         6      185606.6518          -7.4648            4.60m\n",
      "         7      185611.0364           6.5751            4.27m\n",
      "         8      185606.1488          -7.3286            3.94m\n",
      "         9     8702431.6062    12775238.1871            3.61m\n",
      "        10     8702431.0132          -0.8934            3.28m\n",
      "        11           6.0809   -13053637.3981            2.95m\n",
      "        12     8888036.5648    13332045.7319            2.62m\n",
      "        13      185611.0528   -13182295.8674            2.29m\n",
      "        14      185611.1330           0.1250            1.96m\n",
      "        15     8788208.2275    12903895.6414            1.64m\n",
      "        16     8788207.7244          -1.0527            1.31m\n",
      "        17      271382.9511   -12775237.1602           58.89s\n",
      "        18      271382.9593           0.0139           39.26s\n",
      "        19      185611.7129     -128656.8732           19.63s\n",
      "        20      185611.8214        -434.4813            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.9989          -0.0443            6.69m\n",
      "         2           1.0105           0.0080            6.12m\n",
      "         3           1.0220           0.0155            5.72m\n",
      "         4           1.0290     -198855.3433            5.36m\n",
      "         5          43.3558          63.4819            5.00m\n",
      "         6      132328.5837      198396.6984            4.66m\n",
      "         7      132592.0441         395.1927            4.32m\n",
      "         8      132573.8231         -27.3239            3.98m\n",
      "         9      132514.3373         -89.7144            3.65m\n",
      "        10      132580.3590          99.0342            3.32m\n",
      "        11         186.7526     -198590.4069            2.98m\n",
      "        12      897125.4030    -2095340.3973            2.65m\n",
      "        13      897139.9995          21.8954            2.32m\n",
      "        14     1661813.8500     1147010.7721            1.99m\n",
      "        15     2426382.2634     1146852.6185            1.65m\n",
      "        16          72.4774    -3639464.6765            1.32m\n",
      "        17     2426421.7210     3639523.8699           59.49s\n",
      "        18     2426313.6848      -12788.9745           39.64s\n",
      "        19     1668416.4523    -1136845.8448           19.82s\n",
      "        20     1665129.5969       -4930.2830            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.9989          -0.0443            6.83m\n",
      "         2           1.0105           0.0080            6.19m\n",
      "         3           1.0220           0.0155            5.75m\n",
      "         4           1.0290     -198855.3433            5.37m\n",
      "         5          43.3558          63.4819            5.01m\n",
      "         6      132328.5837      198396.6984            4.66m\n",
      "         7      132592.0441         395.1927            4.32m\n",
      "         8      132573.8231         -27.3239            3.98m\n",
      "         9      132514.3373         -89.7144            3.65m\n",
      "        10      132580.3590          99.0342            3.31m\n",
      "        11         186.7526     -198590.4069            2.98m\n",
      "        12      897125.4030    -2095340.3973            2.64m\n",
      "        13      897139.9995          21.8954            2.31m\n",
      "        14     1661813.8500     1147010.7721            1.98m\n",
      "        15     2426382.2634     1146852.6185            1.65m\n",
      "        16          72.4774    -3639464.6765            1.32m\n",
      "        17     2426421.7210     3639523.8699           59.35s\n",
      "        18     2426313.6848      -12788.9745           39.55s\n",
      "        19     1668416.4523    -1136845.8448           19.77s\n",
      "        20     1665129.5969       -4930.2830            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0033          -0.0419            6.83m\n",
      "         2           1.0143      -40217.9447            6.21m\n",
      "         3       26775.3964       39823.1068            5.78m\n",
      "         4       27038.6471   -15726328.6679            5.40m\n",
      "         5           1.0268      -40556.4357            5.08m\n",
      "         6       26888.2093       40121.9979            4.71m\n",
      "         7    10511541.3437    15726827.9891            4.36m\n",
      "         8    10511623.7946         127.8016            4.01m\n",
      "         9    10511720.9930         145.8003            3.66m\n",
      "        10    10511754.1429          49.7211            3.33m\n",
      "        11    10484946.5750      -40211.3505            2.99m\n",
      "        12    10511639.7268       40039.7234            2.66m\n",
      "        13    10511474.9770        -247.1253            2.32m\n",
      "        14    10511645.7582         116.1771            1.99m\n",
      "        15    10511510.9228        -216.2119            1.66m\n",
      "        16         369.4739   -17228000.0540            1.32m\n",
      "        17    11459114.5885    17188117.6568           59.64s\n",
      "        18    10484845.3011    -1461403.9294           39.73s\n",
      "        19         387.3242   -15726686.9550           19.85s\n",
      "        20    11458911.1057    17187785.6706            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0033          -0.0419            6.35m\n",
      "         2           1.0143      -40217.9447            5.93m\n",
      "         3       26775.3964       39823.1068            5.58m\n",
      "         4       27038.6471   -15726328.6679            5.24m\n",
      "         5           1.0268      -40556.4357            4.90m\n",
      "         6       26888.2093       40121.9979            4.57m\n",
      "         7    10511541.3437    15726827.9891            4.24m\n",
      "         8    10511623.7946         127.8016            3.91m\n",
      "         9    10511720.9930         145.8003            3.59m\n",
      "        10    10511754.1429          49.7211            3.26m\n",
      "        11    10484946.5750      -40211.3505            2.93m\n",
      "        12    10511639.7268       40039.7234            2.61m\n",
      "        13    10511474.9770        -247.1253            2.28m\n",
      "        14    10511645.7582         116.1771            1.96m\n",
      "        15    10511510.9228        -216.2119            1.63m\n",
      "        16         369.4739   -17228000.0540            1.30m\n",
      "        17    11459114.5885    17188117.6568           58.68s\n",
      "        18    10484845.3011    -1461403.9294           39.12s\n",
      "        19         387.3242   -15726686.9550           19.56s\n",
      "        20    11458911.1057    17187785.6706            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0075          -0.0456            6.91m\n",
      "         2       13389.5128           0.0298            6.24m\n",
      "         3           1.0228      -20205.2374            5.80m\n",
      "         4          82.6839         122.4923            5.41m\n",
      "         5       13471.1723     -152324.8901            5.05m\n",
      "         6       54676.1275       61807.4354            4.70m\n",
      "         7      128409.4461      110599.9741            4.35m\n",
      "         8       41205.9724     -130805.2123            4.01m\n",
      "         9          82.6883      -61684.9601            3.67m\n",
      "        10      128327.7992      192367.6686            3.33m\n",
      "        11       13471.3343     -172284.7029            3.00m\n",
      "        12      128409.4627      172407.1943            2.66m\n",
      "        13       54594.6025     -110722.2900            2.33m\n",
      "        14           1.1816      -81890.1345            2.00m\n",
      "        15       87204.5088      130804.9838            1.66m\n",
      "        16 417730552426737883879129541714640896.0000 -626595828640106788925206165152858112.0000            1.33m\n",
      "        17 417730552426737883879129541714640896.0000           0.0000           59.95s\n",
      "        18 417730552426737883879129541714640896.0000           0.0000           39.93s\n",
      "        19 835461104853475767758259083429281792.0000 626595828640106788925206165152858112.0000           19.95s\n",
      "        20       73816.0273 -1253191657280213577850412330305716224.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0075          -0.0456            6.48m\n",
      "         2       13389.5128           0.0298            6.00m\n",
      "         3           1.0228      -20205.2374            5.63m\n",
      "         4          82.6839         122.4923            5.28m\n",
      "         5       13471.1723     -152324.8901            4.94m\n",
      "         6       54676.1275       61807.4354            4.60m\n",
      "         7      128409.4461      110599.9741            4.27m\n",
      "         8       41205.9724     -130805.2123            3.94m\n",
      "         9          82.6883      -61684.9601            3.61m\n",
      "        10      128327.7992      192367.6686            3.28m\n",
      "        11       13471.3343     -172284.7029            2.95m\n",
      "        12      128409.4627      172407.1943            2.62m\n",
      "        13       54594.6025     -110722.2900            2.30m\n",
      "        14           1.1816      -81890.1345            1.97m\n",
      "        15       87204.5088      130804.9838            1.64m\n",
      "        16 417730552426737883879129541714640896.0000 -626595828640106788925206165152858112.0000            1.31m\n",
      "        17 417730552426737883879129541714640896.0000           0.0000           58.97s\n",
      "        18 417730552426737883879129541714640896.0000           0.0000           39.30s\n",
      "        19 835461104853475767758259083429281792.0000 626595828640106788925206165152858112.0000           19.65s\n",
      "        20       73816.0273 -1253191657280213577850412330305716224.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0043          -0.0376            6.71m\n",
      "         2           1.0049           0.0037            6.16m\n",
      "         3           1.0078          -0.0048            5.76m\n",
      "         4           1.0222     -278407.6737            5.39m\n",
      "         5      185606.0684   -12775237.3040            5.03m\n",
      "         6      185606.6518          -7.4648            4.68m\n",
      "         7      185611.0364           6.5751            4.34m\n",
      "         8      185606.1488          -7.3286            4.00m\n",
      "         9     8702431.6062    12775238.1871            3.67m\n",
      "        10     8702431.0132          -0.8934            3.33m\n",
      "        11           6.0809   -13053637.3981            2.99m\n",
      "        12     8888036.5648    13332045.7319            2.66m\n",
      "        13      185611.0528   -13182295.8674            2.33m\n",
      "        14      185611.1330           0.1250            1.99m\n",
      "        15     8788208.2275    12903895.6414            1.66m\n",
      "        16     8788207.7244          -1.0527            1.33m\n",
      "        17      271382.9511   -12775237.1602           59.60s\n",
      "        18      271382.9593           0.0139           39.71s\n",
      "        19      185611.7129     -128656.8732           19.85s\n",
      "        20      185611.8214        -434.4813            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           1.0042          -0.0317            6.60m\n",
      "         2           1.0081      -40138.2895            6.07m\n",
      "         3       26759.8696       40138.2951            5.68m\n",
      "         4       26759.8875        -121.8885            5.32m\n",
      "         5           1.0818  -415411197.7708            4.98m\n",
      "         6   276940799.5580   415411197.7211            4.64m\n",
      "         7   276940880.8312         121.9090            4.30m\n",
      "         8   276940880.8185          -0.0142            3.97m\n",
      "         9       26841.2141  -415371063.1719            3.64m\n",
      "        10       26843.7205           3.7629            3.30m\n",
      "        11   276914121.9561   415330917.3110            2.97m\n",
      "        12       26843.6908  -415330917.3881            2.64m\n",
      "        13   276940880.8633   415371055.7658            2.31m\n",
      "        14   276940880.8772           0.0149            1.98m\n",
      "        15       26843.7076  -415371055.7526            1.65m\n",
      "        16           3.5668      -40260.2077            1.32m\n",
      "        17          84.9036         122.0118           59.30s\n",
      "        18   276914121.8809   415371055.4643           39.53s\n",
      "        19           3.5674  -415371177.4653           19.76s\n",
      "        20          84.8314         121.8969            0.00s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "extra_trees = ExtraTreesClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=64,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scorer = make_scorer(precision_at_recall, recall=0.2, average='weighted')\n",
    "\n",
    "scores = cross_val_score(extra_trees, X_sample, y_train, cv=5, scoring=scorer, verbose=1, n_jobs=64)\n",
    "\n",
    "y_pred_cv = cross_val_predict(extra_trees, X_sample, y_train, cv=5, n_jobs=64)\n",
    "\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(\"Cross-Validation Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "print(f\"Mean precision at recall 0.2: {scores.mean():.4f} ± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shortlisting Models\n",
    "\n",
    "1. **Logistic Regression**\n",
    "    - Precision: 0.0681\n",
    "    - Recall: 0.0682\n",
    "    - Precision at Recall 0.2: NA\n",
    "\n",
    "Precision at recall is non existent because it didnt hit our threshold of 0.2. We are hoping that because it was our best model, giving it more data (we trained it on 100k),and fine tuning it will yield better results and hopefully get the threshold over the 0.2 (and ideally hit 0.25)\n",
    "\n",
    "2. **MLP**\n",
    "    - Recall: 0.0556\n",
    "    - Precision: 0.0571\n",
    "    - Precision at Recall 0.2: 0.6195\n",
    "    \n",
    "On the surface this precision at recall is great and got me super excited, however upon further notice its because it just said it was On Time everytime. Hopefully with further tuning and more data it improves. I am mostly picking this one because its a neural network and I want to use one of those even though it was worse "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deni5\\AppData\\Local\\Temp\\ipykernel_10160\\1017157270.py:3: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  preprocessor = pickle.load(f)\n",
      "c:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator SimpleImputer from version 1.5.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator FunctionTransformer from version 1.5.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator ColumnTransformer from version 1.5.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.5.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.5.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator PCA from version 1.5.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 87] The parameter is incorrect",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 370, in _sendback_result\n    result_queue.put(\n  File \"c:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 233, in put\n    self._writer.send_bytes(obj)\n  File \"C:\\Users\\deni5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py\", line 205, in send_bytes\n    self._send_bytes(m[offset:offset + size])\n  File \"C:\\Users\\deni5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\connection.py\", line 285, in _send_bytes\n    ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\nOSError: [WinError 87] The parameter is incorrect\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     preprocessor \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m----> 5\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\pipeline.py:1092\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m   1090\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter():\n\u001b[1;32m-> 1092\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params[name]\u001b[38;5;241m.\u001b[39mtransform)\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Xt\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1101\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[1;32m-> 1101\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_func_on_transformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_dataframe_and_transform_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[0;32m   1111\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:910\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[1;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[0;32m    898\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    899\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    900\u001b[0m             delayed(func)(\n\u001b[0;32m    901\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    907\u001b[0m             )\n\u001b[0;32m    908\u001b[0m         )\n\u001b[1;32m--> 910\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 87] The parameter is incorrect"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('preprocessor.pkl', 'rb') as f:\n",
    "    preprocessor = pickle.load(f)\n",
    "\n",
    "X = preprocessor.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.sample(n=100000, random_state=42)\n",
    "y_train = y_train.sample(n=100000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 147 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deni5\\OneDrive\\Documents\\Courses\\neural_networks\\NeuralNetworkProject\\venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Found: {'C': np.float64(0.1767016940294795), 'fit_intercept': True, 'max_iter': 300, 'multi_class': 'auto', 'penalty': 'l1', 'solver': 'saga', 'tol': np.float64(0.0008319939418114052)}\n",
      "Recall: 0.0516\n",
      "Precision: 0.0657\n",
      "F1 Score: 0.0053\n",
      "Classification Report:\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "            Carrier Cancellation       0.00      0.03      0.01       424\n",
      "      Major Delay - CarrierDelay       0.00      0.05      0.01       514\n",
      " Major Delay - LateAircraftDelay       0.01      0.03      0.01       649\n",
      "          Major Delay - NASDelay       0.00      0.05      0.00        91\n",
      "      Major Delay - WeatherDelay       0.00      0.16      0.00        96\n",
      "     Medium Delay - CarrierDelay       0.01      0.00      0.00      1881\n",
      "Medium Delay - LateAircraftDelay       0.03      0.01      0.01      2886\n",
      "         Medium Delay - NASDelay       0.01      0.05      0.01       487\n",
      "     Medium Delay - WeatherDelay       0.00      0.07      0.01       325\n",
      "      Minor Delay - CarrierDelay       0.03      0.00      0.00      3539\n",
      " Minor Delay - LateAircraftDelay       0.06      0.00      0.00      4238\n",
      "          Minor Delay - NASDelay       0.01      0.00      0.00      1060\n",
      "      Minor Delay - WeatherDelay       0.00      0.11      0.01       326\n",
      "                NAS Cancellation       0.00      0.12      0.00       205\n",
      "                         On-Time       1.00      0.00      0.00     78470\n",
      "                  Security Issue       0.00      0.22      0.00        51\n",
      "                         Unknown       0.00      0.00      0.00      3977\n",
      "            Weather Cancellation       0.01      0.01      0.01       781\n",
      "\n",
      "                        accuracy                           0.00    100000\n",
      "                       macro avg       0.07      0.05      0.01    100000\n",
      "                    weighted avg       0.79      0.00      0.00    100000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision at Recall ≥ 0.2: 0.0000 ± 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_predict, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    recall_score, precision_score, f1_score, classification_report, make_scorer\n",
    ")\n",
    "from scipy.stats import loguniform, uniform\n",
    "\n",
    "precision_at_recall_scorer = make_scorer(\n",
    "    precision_at_recall,\n",
    "    recall=0.2,\n",
    "    average='macro',\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    solver='saga',\n",
    "    max_iter=5000,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=4,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    'C': loguniform(1e-3, 1e3),\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'tol': uniform(1e-4, 1e-3),\n",
    "    'solver': ['saga'],\n",
    "    'fit_intercept': [True],\n",
    "    'max_iter': [300],  \n",
    "    'multi_class': ['auto', 'ovr'],  \n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    log_reg,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,  \n",
    "    scoring=precision_at_recall_scorer,\n",
    "    cv=3,       \n",
    "    verbose=1,\n",
    "    n_jobs=4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X, y_train)\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "y_pred_cv = cross_val_predict(best_model, X, y_train, cv=3, n_jobs=4)\n",
    "\n",
    "recall = recall_score(y_train, y_pred_cv, average='macro')\n",
    "precision = precision_score(y_train, y_pred_cv, average='macro', zero_division=0)\n",
    "f1 = f1_score(y_train, y_pred_cv, average='macro')\n",
    "\n",
    "print(\"Best Parameters Found:\", random_search.best_params_)\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred_cv, zero_division=0))\n",
    "\n",
    "custom_cv_scores = cross_val_score(\n",
    "    best_model,\n",
    "    X,\n",
    "    y_train,\n",
    "    cv=3,\n",
    "    scoring=precision_at_recall_scorer,\n",
    "    n_jobs=4,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"Mean Precision at Recall ≥ 0.2: {custom_cv_scores.mean():.4f} ± {custom_cv_scores.std():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
